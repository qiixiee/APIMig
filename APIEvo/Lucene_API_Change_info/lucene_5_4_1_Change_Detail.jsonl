{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6918", "change_description": ": LRUQueryCache.onDocIdSetEviction is only called when at least\none DocIdSet is being evicted.", "change_title": "LRUQueryCache.onDocIdSetEviction should not be called when nothing is evicted", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "This method is confusing because it states it will be called \"when one or more DocIdSets are removed from this cache\" but may actually be called with zero docidsets when evicting a per-segment cache that did not contain any entries.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12775538/LUCENE-6918.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6946", "change_description": ": SortField.equals now takes the missingValue parameter into\naccount.", "change_title": "SortField.equals does not take the missing value into account", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "SortField.equals does not check whether both objects have the same missing value.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779042/LUCENE-6946.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "SOLR-7865", "change_description": ": BlendedInfixSuggester was returning too many results", "change_title": "lookup method implemented in BlendedInfixLookupFactory does not respect suggest.count", "detail_type": "Bug", "detail_affect_versions": "5.2.1", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "The following test failes in the TestBlendedInfixSuggestions.java: This is mainly because get called multiple times from  https://github.com/apache/lucene-solr/blob/trunk/solr/core/src/java/org/apache/solr/spelling/suggest/fst/BlendedInfixLookupFactory.java#L118 The test is expecting count=1 but we get all 3 docs out.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12778467/LUCENE_7865.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6929", "change_description": ": Fix SpanNotQuery rewriting to not drop the pre/post parameters.", "change_title": "Multiterm within a SpanNotQuery no longer working", "detail_type": "Bug", "detail_affect_versions": "5.4,6.0", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "Some unit tests in LUCENE-5205 that passed in 5.3.1 are now failing with Lucene 5.4.0. It looks like MultiTerms are no longer being processed correctly within a SpanNotQuery in 5.4.0 and in trunk.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12777569/LUCENE_6929.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6910", "change_description": ": fix 'if ... > Integer.MAX_VALUE' check in\n(Binary|Numeric)DocValuesFieldUpdates.merge\n(", "change_title": "fix 2 interesting and 2 trivial issues found by \"Coverity scan results of Lucene\"", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "https://scan.coverity.com/projects/5620 mentioned on the dev mailing list (http://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3cCAFTwexg51-jm_6MDEoz1rEagN3xgkBeTOz5OU_f+mELbOO1POw@mail.gmail.com%3e) in July 2015:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12774351/LUCENE-6910.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "https://scan.coverity.com/projects/5620", "change_description": ": fix 'if ... > Integer.MAX_VALUE' check in\n(Binary|Numeric)DocValuesFieldUpdates.merge\n(", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6950", "change_description": ": Fix FieldInfos handling of UninvertingReader, e.g. do not\nhide the true docvalues update generation or other properties.", "change_title": "DimensionalRangeQuery not working with UninvertingReader", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "As I was trying out dimensional fields for SOLR-8396, I realized that DimensionalRangeQuery is not working with UninvertingReader.  In Solr, all directory readers are wrapped by an UninvertingReader and an ExitableDirectoryReader. Here's the error: Here's an example program to trigger this failure: I don't yet know more as to why this could be. mikemccand Any ideas, please? Apologies if I should've brought this up in the mailing lists, or as a comment in LUCENE-6917 itself.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779763/LUCENE-6950.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6948", "change_description": ": Fix ArrayIndexOutOfBoundsException in PagedBytes$Reader.fill\nby removing an unnecessary long-to-int cast.", "change_title": "ArrayIndexOutOfBoundsException in PagedBytes$Reader.fill", "detail_type": "Bug", "detail_affect_versions": "4.10.4", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "With a very large index (in our case > 10G), we are seeing exceptions like: java.lang.ArrayIndexOutOfBoundsException: -62400 \tat org.apache.lucene.util.PagedBytes$Reader.fill(PagedBytes.java:116) \tat org.apache.lucene.search.FieldCacheImpl$BinaryDocValuesImpl$1.get(FieldCacheImpl.java:1342) \tat org.apache.lucene.search.join.TermsCollector$SV.collect(TermsCollector.java:106) \tat org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:193) \tat org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:163) \tat org.apache.lucene.search.BulkScorer.score(BulkScorer.java:35) \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:621) \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:309) The code in question is trying to allocate an array with a negative size.  We believe the source of the error is in org.apache.lucene.search.FieldCacheImpl$BinaryDocValuesImpl$1.get where the following code occurs: final int pointer = (int) docToOffset.get(docID);           if (pointer == 0) else", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779423/LUCENE-6948.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-6970", "change_description": ": Fixed off-by-one error in Lucene54DocValuesProducer that could\npotentially corrupt doc values.", "change_title": "Off-by-one error in Lucene54DocValuesProducer", "detail_type": "Bug", "detail_affect_versions": "5.4", "detail_fix_versions": "5.4.1,5.5,6.0", "detail_description": "This was found by this build failure: http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/15210/ If the doc count is a multiple of 65534 minus one and the segment is storing binary, sorted set or sorted numeric doc values then you may hit an error when reading values that is due to an off-by-one error in Lucene54DocValuesProducer. This was introduced in LUCENE-6840. I'll upload a patch shortly.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12781564/LUCENE-6970.patch", "patch_content": "none"}
{"library_version": "5.4.1", "change_type": "Bug Fixes", "change_id": "LUCENE-2229", "change_description": ": Fix Highlighter's SimpleSpanFragmenter when multiple adjacent\nstop words following a span can unduly make the fragment way too long.", "change_title": "SimpleSpanFragmenter fails to start a new fragment", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.1,5.5", "detail_description": "SimpleSpanFragmenter fails to identify a new fragment when there is more than one stop word after a span is detected. This problem can be observed when the Query contains a PhraseQuery. The problem is that the span extends toward the end of the TokenGroup. This is because waitForProps = positionSpans.get.end + 1; and position += posIncAtt.getPositionIncrement(); this generates a value of position greater than the value of waitForProps and (waitForPos == position) never matches. An example is provided in the test case for the following Document and the query \"all tokens\" followed by the words of a. \"Attribute instances are reused for all tokens of a document. Thus, a TokenStream/-Filter needs to update the appropriate Attribute(s) in incrementToken(). The consumer, commonly the Lucene indexer, consumes the data in the Attributes and then calls incrementToken() again until it retuns false, which indicates that the end of the stream was reached. This means that in each call of incrementToken() a TokenStream/-Filter can safely overwrite the data in the Attribute instances.\" are reused for <B>all</B> <B>tokens</B> of a document. Thus, a TokenStream/-Filter needs to update the appropriate Attribute(s) in incrementToken(). The consumer, commonly the Lucene indexer, consumes the data in the Attributes and then calls incrementToken() again until it retuns false, which indicates that the end of the stream was reached. This means that in each call of incrementToken() a TokenStream/-Filter can safely overwrite the data in the Attribute instances. for <B>all</B> <B>tokens</B> of a document", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779764/LUCENE-2229.patch", "patch_content": "none"}
