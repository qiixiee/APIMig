{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5907", "change_description": ": Fix corruption case when opening a pre-4.x index with\nIndexWriter, then opening an NRT reader from that writer, then\ncalling commit from the writer, then closing the NRT reader.  This\ncase would remove the wrong files from the index leading to a\ncorrupt index.", "change_title": "closing NRT reader after upgrading from 3.x index can cause index corruption", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "I have a small test case showing the issue.... I think we should fix this for 4.10?", "patch_link": "https://issues.apache.org/jira/secure/attachment/12664417/LUCENE-5907.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5919", "change_description": ": Fix exception handling inside IndexWriter when\ndeleteFile throws an exception, to not over-decRef index files,\npossibly deleting a file that's still in use in the index, leading\nto corruption.", "change_title": "More carefully handle exceptions from IndexFileDeleter.decRef", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.9.1,4.10.1,5.0,6.0", "detail_description": "From test failure: https://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/613/ What happened was IW was trying to decRef a set of files, and at least one needed to be deleted, then virus checker threw exception, and IW later passed the full set of files back to decRef later despite that some had already been decRef'd the first time.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12666186/LUCENE-5919.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5922", "change_description": ": DocValuesDocIdSet on 5.x and FieldCacheDocIdSet on 4.x\nare not cacheable.", "change_title": "DocValuesDocIdSet is not cacheable", "detail_type": "Bug", "detail_affect_versions": "4.10", "detail_fix_versions": "4.9.1,4.10.1,5.0,6.0", "detail_description": "This DocIdSet claims it is cacheable although bad things could happen if it was cached since it is not thread-safe and keeps handles to open files. The fix is simple, especially given that this doc id set is cheap to create. But I'm wondering if there is a way we could protect ourselves from such bugs in the future.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12666476/LUCENE-5922.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5843", "change_description": ": Added IndexWriter.MAX_DOCS which is the maximum number\nof documents allowed in a single index, and any operations that add\ndocuments will now throw IllegalStateException if the max count\nwould be exceeded, instead of silently creating an unusable\nindex.", "change_title": "IndexWriter should refuse to create an index with more than INT_MAX docs", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "It's more and more common for users these days to create very large indices, e.g.  indexing lines from log files, or packets on a network, etc., and it's not hard to accidentally exceed the maximum number of documents in one index. I think the limit is actually Integer.MAX_VALUE-1 docs, because we use that value as a sentinel during searching. I'm not sure what IW does today if you create a too-big index but it's probably horrible; it may succeed and then at search time you hit nasty exceptions when we overflow int. I think it should throw an IndexFullException instead.  It'd be nice if we could do this on the very doc that when added would go over the limit, but I would also settle for just throwing at flush as well ... i.e. I think what's really important is that the index does not become unusable.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12658412/LUCENE-5843.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5844", "change_description": ": ArrayUtil.grow/oversize now returns a maximum of\nInteger.MAX_VALUE - 8 for the maximum array size.", "change_title": "ArrayUtil.grow should not pretend you can actually allocate array[Integer.MAX_VALUE]", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "Today if the growth it wants would exceed Integer.MAX_VALUE, it returns Integer.MAX_VALUE, but you can't actually allocate arrays this large; the actual limit is JVM dependent and varies across JVMs ... It would be nice if we could somehow \"introspect\" the JVM to find out what its  actual limit is and use that.  http://stackoverflow.com/questions/3038392/do-java-arrays-have-a-maximum-size seems to imply that using Integer.MAX_VALUE - 8 may be \"safe\" (it's what ArrayList.java apparently uses).", "patch_link": "https://issues.apache.org/jira/secure/attachment/12657419/LUCENE-5844.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5827", "change_description": ": Make all Directory implementations correctly fail with\nIllegalArgumentException if slices are out of bounds.", "change_title": "Make all Directory implementations correctly fail with IllegalArgumentException if slices are out of bounds", "detail_type": "Bug", "detail_affect_versions": "4.8,4.9", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "After implementing LUCENE-5681, I noticed, that some directory implementations (like NIOFSDirectory) do not do bounds checks on slice creation. We should do this to early detect bugs, if file formats break because of index corrumption. This test in BaseDirectoryTestCase does not pass for all directory impls:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12656008/LUCENE-5827.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5897", "change_description": ",", "change_title": "performance bug (\"adversary\") in StandardTokenizer", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "There seem to be some conditions (I don't know how rare or what conditions) that cause StandardTokenizer to essentially hang on input: I havent looked hard yet, but as its essentially a DFA I think something wierd might be going on. An easy way to reproduce is with 1MB of underscores, it will just hang forever.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12663628/LUCENE-5897.patch", "patch_content": "none"}
{"library_version": "4.9.1", "change_type": "Bug fixes", "change_id": "LUCENE-5400", "change_description": ",", "change_title": "Long text matching email local-part rule in UAX29URLEmailTokenizer causes extremely slow tokenization", "detail_type": "Bug", "detail_affect_versions": "4.5", "detail_fix_versions": "4.9.1,4.10,6.0", "detail_description": "This is a pretty nasty bug, and causes the cluster to stop accepting updates. I'm not sure how to consistently reproduce it but I have done so numerous times. Switching to a whitespace tokenizer improved indexing speed, and I never got the issue again. I'm running a 4.6 Snapshot - I had issues with deadlocks with numerous versions of Solr, and have finally narrowed down the problem to this code, which affects many/all versions of Solr. When the thread hits this issue it uses 100% CPU, restarting the node which has the error allows indexing to continue until hit again. Here is thread dump: http-bio-8080-exec-45 (201) org.apache.lucene.analysis.standard.UAX29URLEmailTokenizerImpl.getNextToken​(UAX29URLEmailTokenizerImpl.java:4343)     org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer.incrementToken​(UAX29URLEmailTokenizer.java:147)     org.apache.lucene.analysis.util.FilteringTokenFilter.incrementToken​(FilteringTokenFilter.java:82)     org.apache.lucene.analysis.core.LowerCaseFilter.incrementToken​(LowerCaseFilter.java:54)     org.apache.lucene.index.DocInverterPerField.processFields​(DocInverterPerField.java:174)     org.apache.lucene.index.DocFieldProcessor.processDocument​(DocFieldProcessor.java:248)     org.apache.lucene.index.DocumentsWriterPerThread.updateDocument​(DocumentsWriterPerThread.java:253)     org.apache.lucene.index.DocumentsWriter.updateDocument​(DocumentsWriter.java:453)     org.apache.lucene.index.IndexWriter.updateDocument​(IndexWriter.java:1517)     org.apache.solr.update.DirectUpdateHandler2.addDoc​(DirectUpdateHandler2.java:217)     org.apache.solr.update.processor.RunUpdateProcessor.processAdd​(RunUpdateProcessorFactory.java:69)     org.apache.solr.update.processor.UpdateRequestProcessor.processAdd​(UpdateRequestProcessor.java:51)     org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd​(DistributedUpdateProcessor.java:583)     org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd​(DistributedUpdateProcessor.java:719)     org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd​(DistributedUpdateProcessor.java:449)     org.apache.solr.handler.loader.JavabinLoader$1.update​(JavabinLoader.java:89)     org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readOuterMostDocIterator​(JavaBinUpdateRequestCodec.java:151)     org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readIterator​(JavaBinUpdateRequestCodec.java:131)     org.apache.solr.common.util.JavaBinCodec.readVal​(JavaBinCodec.java:221)     org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readNamedList​(JavaBinUpdateRequestCodec.java:116)     org.apache.solr.common.util.JavaBinCodec.readVal​(JavaBinCodec.java:186)     org.apache.solr.common.util.JavaBinCodec.unmarshal​(JavaBinCodec.java:112)     org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec.unmarshal​(JavaBinUpdateRequestCodec.java:158)     org.apache.solr.handler.loader.JavabinLoader.parseAndLoadDocs​(JavabinLoader.java:99)     org.apache.solr.handler.loader.JavabinLoader.load​(JavabinLoader.java:58)     org.apache.solr.handler.UpdateRequestHandler$1.load​(UpdateRequestHandler.java:92)     org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody​(ContentStreamHandlerBase.java:74)     org.apache.solr.handler.RequestHandlerBase.handleRequest​(RequestHandlerBase.java:135)     org.apache.solr.core.SolrCore.execute​(SolrCore.java:1859)     org.apache.solr.servlet.SolrDispatchFilter.execute​(SolrDispatchFilter.java:703)     org.apache.solr.servlet.SolrDispatchFilter.doFilter​(SolrDispatchFilter.java:406)     org.apache.solr.servlet.SolrDispatchFilter.doFilter​(SolrDispatchFilter.java:195)     org.apache.catalina.core.ApplicationFilterChain.internalDoFilter​(ApplicationFilterChain.java:243)     org.apache.catalina.core.ApplicationFilterChain.doFilter​(ApplicationFilterChain.java:210)     org.apache.catalina.core.StandardWrapperValve.invoke​(StandardWrapperValve.java:222)     org.apache.catalina.core.StandardContextValve.invoke​(StandardContextValve.java:123)     org.apache.catalina.core.StandardHostValve.invoke​(StandardHostValve.java:171)     org.apache.catalina.valves.ErrorReportValve.invoke​(ErrorReportValve.java:99)     org.apache.catalina.valves.AccessLogValve.invoke​(AccessLogValve.java:953)     org.apache.catalina.core.StandardEngineValve.invoke​(StandardEngineValve.java:118)     org.apache.catalina.connector.CoyoteAdapter.service​(CoyoteAdapter.java:408)     org.apache.coyote.http11.AbstractHttp11Processor.process​(AbstractHttp11Processor.java:1023)     org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process​(AbstractProtocol.java:589)     org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run​(JIoEndpoint.java:312)     java.util.concurrent.ThreadPoolExecutor.runWorker​(Unknown Source)     java.util.concurrent.ThreadPoolExecutor$Worker.run​(Unknown Source)     java.lang.Thread.run​(Unknown Source)", "patch_link": "none", "patch_content": "none"}
