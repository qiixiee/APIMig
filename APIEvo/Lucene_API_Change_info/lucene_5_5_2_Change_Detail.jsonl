{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7065", "change_description": ": Fix the explain for the global ordinals join query. Before the\nexplain would also indicate that non matching documents would match.\nOn top of that with score mode average, the explain would fail with a NPE.", "change_title": "Fix explain for global ordinal query time join", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0", "detail_description": "The explain methods for the global ordinal join is broken, because even in the case that a document doesn't match with the query it tries to create an explain that tells it does. In the case when score mode 'avg' is used this causes a NPE and in the other cases the return explanation indicates that a document matches while it doesn't.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12791435/LUCENE_7065.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7111", "change_description": ": DocValuesRangeQuery.newLongRange behaves incorrectly for\nLong.MAX_VALUE and Long.MIN_VALUE", "change_title": "DocValuesRangeQuery.newLongRange behaves incorrectly for Long.MAX_VALUE and Long.MIN_VALUE", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0,6.1,7.0", "detail_description": "It seems that the following queries return all documents, which is unexpected: In Solr, floats and doubles are converted to longs and -0d gets converted to Long.MIN_VALUE, and queries like {-0d TO 0d] could fail due to this, returning all documents in the index.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12793908/LUCENE-7111.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7139", "change_description": ": Fix bugs in geo3d's Vincenty surface distance\nimplementation", "change_title": "Geo3d Vincenty distance method broken", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0,6.1,7.0", "detail_description": "There is a PlanetModel.surfaceDistance() method in Geo3D that computes the Vincenty distance.  This is mostly a convenience but is also reasonable to  include for tests.  The current implementation, however, is broken.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12795398/LUCENE-7139.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7187", "change_description": ": Block join queries' Weight#extractTerms(...) implementations\nshould delegate to the wrapped weight.", "change_title": "Block join queries' weight impl should implement extractTerms(...)", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.1,6.1", "detail_description": "In the case the distribute document frequencies need to be computed for block join queries, the child query is ignored.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12797498/LUCENE_7187.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7279", "change_description": ": JapaneseTokenizer throws ArrayIndexOutOfBoundsException\non some valid inputs", "change_title": "AIOOBE from JapaneseTokenizer", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.1,7.0", "detail_description": "On certain Japanese input strings you can hit this: I have a patch with a test case and fix.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12803488/LUCENE-7279.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7219", "change_description": ": Make queryparser/xml (Point|LegacyNumeric)RangeQuery builders\nmatch the underlying queries' (lower|upper)Term optionality logic.", "change_title": "(Point|LegacyNumeric)RangeQuery builders to match queries' (lower|upper)Term optionality logic", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.1,6.1,7.0", "detail_description": "Currently the (Point|LegacyNumeric)RangeQuery queries themselves support (lower|upper)Term optionality e.g. the lowerTerm could be omitted but the (Point|LegacyNumeric)RangeQueryBuilder builders mandate (lower|upper)Term attributes. This mismatch seems unintended. Proposed patch for ...QueryBuilder logic to match ...Query logic to follow.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12798966/LUCENE-7219.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7284", "change_description": ": GapSpans needs to implement positionsCost().", "change_title": "UnsupportedOperationException wrt SpanNearQuery with Gap (Needed for Synonym Query Expansion)", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.1,6.1", "detail_description": "I am trying to support synonyms on the query side by doing  query expansion. For example, the query \"open webpage\" can be expanded if the following  things are synonyms: \"open\" | \"go to\" This becomes the following: (I'm using both the stop word filter and the  stemming filter) Notice that \"go to\" became just \"go\", because apparently \"to\" is removed  by the stop word filter. Interestingly, if you turn \"go to webpage\" into a phrase, you get \"go ?  webpage\", but if you turn \"go to\" into a phrase, you just get \"go\",  because apparently a trailing stop word in a PhraseQuery gets dropped.  (there would actually be no way to represent the gap currently because  it represents gaps implicitly via the position of the phrase tokens, and  if there is no second token, there's no way to implicitly indicate that  there is a gap there) The above query then fails to match \"go to webpage\", because \"go to  webpage\" in the index tokenizes as \"go _ webpage\", and the query,  because it lost its gap, tried to only match \"go webpage\". To try and work around that, I represent \"go to\" not as a phrase, but as  a SpanNearQuery, like this: However, when I run that query, I get the following: ... and when I look up that GapSpans class in SpanNearQuery.java, I see: I asked this question on the mailing list on May 14 and was directed to submit a bug here. This issue is of relatively high priority for us, since this represents the most promising technique we have for supporting synonyms on top of Lucene. (since the SynonymFilter suffers serious issues wrt multi-word synonyms)", "patch_link": "https://issues.apache.org/jira/secure/attachment/12804379/LUCENE-7284.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7231", "change_description": ": WeightedSpanTermExtractor didn't deal correctly with single-term\nphrase queries.", "change_title": "Problem with NGramAnalyzer, PhraseQuery and Highlighter", "detail_type": "Bug", "detail_affect_versions": "5.4.1", "detail_fix_versions": "5.5.2,5.6,6.0.1,6.1", "detail_description": "Using the Highlighter with N-GramAnalyzer and PhraseQuery and searching for a substring with length = N yields the following exception: Below is a JUnit-Test reproducing this behavior. In case of searching for a string with more than N characters or using NGramPhraseQuery this problem doesn't occur. Why is it that more than 1 subSpans are required?", "patch_link": "https://issues.apache.org/jira/secure/attachment/12804392/LUCENE-7231.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7301", "change_description": ": Multiple doc values updates to the same document within\none update batch could be applied in the wrong order resulting in\nthe wrong updated value", "change_title": "updateNumericDocValue mixed with updateDocument can cause data loss in some randomized testing", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.2,6.1,7.0", "detail_description": "SOLR-5944 has been held up by a while due to some extremely rare randomized test failures. Ishan and I have been working on whitling those Solr test failures down, trying to create more isolated reproducable test failures, and i think i've tracked it down to a bug in IndexWriter when the client calls to updateDocument intermixed with calls to updateNumericDocValue AND IndexWriterConfig.setMaxBufferedDocs is very low (i suspect \"how low\" depends on the number of quantity/types of updates â€“ but just got something that reproduced, and haven't tried reproducing with higher values of maxBufferedDocs and larger sequences of updateDocument / updateNumericDocValue calls.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12806804/LUCENE-7301.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7132", "change_description": ": BooleanQuery sometimes assigned too-low scores in cases\nwhere ranges of documents had only a single clause matching while\nother ranges had more than one clause matching", "change_title": "BooleanQuery scores can be diff for same docs+sim when using coord (disagree with Explanation which doesn't change)", "detail_type": "Bug", "detail_affect_versions": "5.5", "detail_fix_versions": "5.5.2,6.1,7.0", "detail_description": "Some of the folks reported that sometimes explain's score can be different than the score requested by fields parameter. Interestingly, Explain's scores would create a different ranking than the original result list. This is something users experience, but it cannot be re-produced deterministically.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12795042/SOLR-8884.patch", "patch_content": "none"}
{"library_version": "5.5.2", "change_type": "Bug Fixes", "change_id": "LUCENE-7291", "change_description": ": Spatial heatmap faceting could mis-count when the heatmap crosses the\ndateline and indexed non-point shapes are much bigger than the heatmap region.", "change_title": "HeatmapFacetCounter bug with dateline and large non-point shapes", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5.2,5.6,6.0.2,6.1", "detail_description": "Jenkins found a test failure today. This reproduces for me (master, java 8): ant test  -Dtestcase=HeatmapFacetCounterTest -Dtests.method=testRandom -Dtests.seed=3EC907D1784B6F23 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=is-IS -Dtests.timezone=Europe/Tirane -Dtests.asserts=true -Dtests.file.encoding=UTF-8", "patch_link": "https://issues.apache.org/jira/secure/attachment/12809501/LUCENE_7291.patch", "patch_content": "none"}
