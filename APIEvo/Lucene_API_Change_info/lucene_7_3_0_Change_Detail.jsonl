{"library_version": "7.3.0", "change_type": "API Changes", "change_id": "LUCENE-8051", "change_description": ": LevensteinDistance renamed to LevenshteinDistance.", "change_title": "Typo in LevensHtein distance", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Looking into an issue in elasticsearch I notices that the Levenshtein distance in lucene is called  LevensteinDistance instead of LevenshteinDistance. The algorithm name contains an H and in the rest of the code the Levenshtein name is spelled correctly with an H.", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "API Changes", "change_id": "LUCENE-8099", "change_description": ": Deprecate CustomScoreQuery, BoostedQuery and BoostingQuery.\nUsers should instead use FunctionScoreQuery, possibly combined with\na lucene expression", "change_title": "Deprecate CustomScoreQuery, BoostedQuery and BoostingQuery", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "After LUCENE-7998, these three queries can all be replaced by a FunctionScoreQuery.  Using lucene-expressions makes them much easier to use as well.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12902659/LUCENE-8099.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "API Changes", "change_id": "LUCENE-8104", "change_description": ": Remove facets module compile-time dependency on queries", "change_title": "Facet module should no longer depend on Queries module (ValueSource)", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "The Grouping module depends on the Queries module in GroupingSearch / ValueSourceGroupSelector to use the ValueSource framework.  It should instead use the newer DoubleValueSource or LongValueSource framework in Core.  As I write this, this appears to be the last part of Lucene to refer to the ValueSource framework, and I think we should then remove it – for another issue of course.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12902810/LUCENE-8104.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "API Changes", "change_id": "LUCENE-8145", "change_description": ": UnifiedHighlighter now uses a unitary OffsetsEnum rather\nthan a list of enums", "change_title": "UnifiedHighlighter should use single OffsetEnum rather than List<OffsetEnum>", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "The UnifiedHighlighter deals with several different aspects of highlighting: finding highlight offsets, breaking content up into snippets, and passage scoring.  It would be nice to split this up so that consumers can use them separately. As a first step, I'd like to change the API of FieldOffsetStrategy to return a single unified OffsetsEnum, rather than a collection of them.  This will make it easier to expose the OffsetsEnum of a document directly from the highlighter, bypassing snippet extraction and scoring.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12908599/LUCENE-8145.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "New Features", "change_id": "LUCENE-2899", "change_description": ": Add new module analysis/opennlp, with analysis components\nto perform tokenization, part-of-speech tagging, lemmatization and phrase\nchunking by invoking the corresponding OpenNLP tools. Named entity\nrecognition is also provided as a Solr update request processor.", "change_title": "Add OpenNLP Analysis capabilities as a module", "detail_type": "New Feature", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Now that OpenNLP is an ASF project and has a nice license, it would be nice to have a submodule (under analysis) that exposed capabilities for it. Drew Farris, Tom Morton and I have code that does: We are also planning a Tokenizer/TokenFilter that can put parts of speech as either payloads (PartOfSpeechAttribute?) on a token or at the same position. I'd propose it go under: modules/analysis/opennlp", "patch_link": "https://issues.apache.org/jira/secure/attachment/12571282/LUCENE-2899-RJN.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "New Features", "change_id": "LUCENE-8126", "change_description": ": Add new spatial prefix tree (SPT) based on google S2 geometry.\nIt can only be used currently with Geo3D spatial context and it provides\nimprovements on indexing time for non-points shapes and on query performance.", "change_title": "Spatial prefix tree based on S2 geometry", "detail_type": "New Feature", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Hi dsmiley, I have been working on a prefix tree based on goggle S2 geometry (https://s2geometry.io/) to be used mainly with Geo3d shapes with very promising results, in particular for complex shapes (e.g polygons). Using this pixelization scheme reduces the size of the index, improves the performance of the queries and reduces the loading time for non-point shapes. If you are ok with this contribution and before providing any code I would like to understand what is the correct/prefered approach: 1) Add new depency to the S2 library (https://mvnrepository.com/artifact/io.sgr/s2-geometry-library-java). It has Apache 2.0 license so it should be ok. 2) Create a utility class with all methods necessary to navigate the S2 tree and create shapes from S2 cells (basically port what we need from the library into Lucene). What do you think?", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8081", "change_description": ": Allow IndexWriter to opt out of flushing on indexing threads\nIndex/Update Threads try to help out flushing pending document buffers to\ndisk. This change adds an expert setting to opt ouf of this behavior unless\nflusing is falling behind.", "change_title": "Allow IndexWriter to opt out of flushing on indexing threads", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Today indexing / updating threads always help out flushing. Experts might want indexing threads to only help flushing if flushes are falling behind. Maybe we can allow an expert flag in IWC to opt out of this behavior.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12901076/LUCENE-8081.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8086", "change_description": ": spatial-extras Geo3dFactory: Use GeoExactCircle with\nconfigurable precision for non-spherical planet models.", "change_title": "G3d wrapper: Improve circles for non spherical planets", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "Hi dsmiley, The purpose of this ticket is to add a new circle shape (GeoExactCircle) for non-spherical planets and therefore remove the method relate from Geo3dCircleShape. The patch will include some simplifications on the wrapper and some refactoring of the tests. I will open shortly a pull request.", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8093", "change_description": ": TrimFilterFactory implements MultiTermAwareComponent", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8094", "change_description": ": TermInSetQuery.toString now returns \"field:(A B C)\"", "change_title": "Improve TermInSetQuery.toString", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Today a TermInSetQuery on field F and terms A, B, C returns this from toString: But this gets misleading when you embed it in a BooleanQuery as a negated clause, which then renders like this: Making it look like only the first clause is negated when in fact they all are. So ... I'd like to instead change it to: I know Query.toString is simply best-effort, is not guaranteed to make something you can then parse in any query parser back to itself, etc., but I think we should still try to make a string that is not misleading when humans stare at it?", "patch_link": "https://issues.apache.org/jira/secure/attachment/12902494/LUCENE-8094.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8121", "change_description": ": UnifiedHighlighter passage relevancy is improved for terms that are\nposition sensitive (e.g. part of a phrase) by having an accurate freq.", "change_title": "UnifiedHighlighter can highlight terms within SpanNear clauses at unmatched positions", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "The UnifiedHighlighter (and original Highlighter) highlight phrases by converting to a SpanQuery and using the Spans start and end positions to assume that every occurrence of the underlying terms between those positions are to be highlighted.  But this is inaccurate; see LUCENE-5455 for a good example, and also LUCENE-2287.  The solution is to use the SpanCollector API which was introduced after the phrase matching aspects of those highlighters were developed.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12905351/LUCENE-2287_UH_SpanCollector.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8129", "change_description": ": A Unicode set filter can now be specified when using ICUFoldingFilter.", "change_title": "Support for defining a Unicode set filter when using ICUFoldingFilter", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "trunk,7.3", "detail_description": "While ICUNormalizer2FilterFactory supports a filter attribute to define a Unicode set filter, ICUFoldingFilterFactory does not support it. A filter allows one to e.g. exclude a set of characters from being folded. E.g. for Finnish and Swedish the filter could be defined like this: <filter class=\"solr.ICUFoldingFilterFactory\" filter=\"[^åäöÅÄÖ]\"/> Note: An additional MappingCharFilterFactory or solr.LowerCaseFilterFactory would be needed for lowercasing the characters excluded from folding. This is similar to what ElasticSearch provides (see https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-icu-folding.html). I'll add a patch that does this similar to ICUNormalizer2FilterFactory. Applies at least to master and branch_7x.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12906081/LUCENE-8129.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-7966", "change_description": ": Build Multi-Release JARs to enable usage of optimized intrinsic methods\nfrom Java 9 for index bounds checking and array comparison/mismatch. This change\nintroduces Java 8 replacements for those Java 9 methods and patches the compiled\nclasses to use the optimized variants through the MR-JAR mechanism.", "change_title": "build mr-jar and use some java 9 methods if available", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "See background: http://openjdk.java.net/jeps/238 It would be nice to use some of the newer array methods and range checking methods in java 9 for example, without waiting for lucene 10 or something. If we build an MR-jar, we can start migrating our code to use java 9 methods right now, it will use optimized methods from java 9 when thats available, otherwise fall back to java 8 code. This patch adds: It sets these up in org.apache.lucene.future as 1-1 mappings to java methods. This way, we can simply directly replace call sites with java 9 methods when java 9 is a minimum. Simple 1-1 mappings mean also that we only have to worry about testing that our java 8 fallback methods work. I found that many of the current byte array methods today are willy-nilly and very lenient for example, passing invalid offsets at times and relying on compare methods not throwing exceptions, etc. I fixed all the instances in core/codecs but have not looked at the problems with AnalyzingSuggester. Also SimpleText still uses a silly method in ArrayUtil in similar crazy way, have not removed that one yet.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12886960/LUCENE-7966.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8127", "change_description": ": Speed up rewriteNoScoring when there are no MUST clauses.", "change_title": "BooleanQuery with needsScores=false, rewriteNoScoring improvement", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "In the case needsScores=false, createWeight calls rewriteNoScoring before creating a new BooleanWeight. This in all cases creates a new BooleanQuery, even when it's not necessary (aka there are no MUST clauses). The rewriteNoScoring method could check for something as simple as if (clauseSets.get(Occur.MUST).size() > 0)  before creating a brand new BooleanQuery.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12910121/LUCENE-8127.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8152", "change_description": ": Improve consumption of doc-value iterators.", "change_title": "Simplify conditionals in JoinUtil", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "The following could be simplified, on line 249: To:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12909081/LUCENE-8152.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8033", "change_description": ": FieldInfos now always use a dense encoding.", "change_title": "Should FieldInfos always use a dense encoding?", "detail_type": "Wish", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Spin-off from LUCENE-8018. The dense vs. sparse encoding logic of FieldInfos introduces  complexity. Given that the sparse encoding is only used when less than 1/16th of fields are used, which sounds uncommon to me, maybe we should use a dense encoding all the time?", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Improvements", "change_id": "LUCENE-8190", "change_description": ": Specialized cell interface to allow any spatial prefix tree to\nbenefit from the setting setPruneLeafyBranches on RecursivePrefixTreeStrategy.", "change_title": "Replace dependency on LegacyCell for setting pruneLeafyBranches on RecursivePrefixTreeStrategy", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "The setting pruneLeafyBranches on RecursivePrefixTreeStrategy depends on abstract class LegacyCell and therefore trees like the newly added S2PrefixTree cannot benefit for such optimization. It is proposed to add a new specialize interface for cell interface and make the setting depends on it instead of LegacyCell.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12912952/LUCENE-8190.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8077", "change_description": ": Fixed bug in how CheckIndex verifies doc-value iterators.", "change_title": "Integer remainder modulo 1 problem in /core/src/java/org/apache/lucene/index/CheckIndex.java", "detail_type": "Bug", "detail_affect_versions": "7.1", "detail_fix_versions": "7.3,8.0", "detail_description": "At  /core/src/java/org/apache/lucene/index/CheckIndex.java: 2198  The branch condition : is always true.  Did you mean (exp & 1) or (exp % 2) instead? The related code is show below:", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "SOLR-11758", "change_description": ": Fixed FloatDocValues.boolVal to correctly return true for all values != 0.0F", "change_title": "Missing boolVal implementation in FloatDocValues", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "In case of DoubleDocValues, boolVal(int doc) has been implemented but this is missing in case FloatDocValues. Impact: For any DocValues which extends FloatDocValues and doesn't implement boolVal(int doc), parent boolVal in FucntionValues would be called. boolVal implementation in FunctionValues Let me know if I can work on it", "patch_link": "https://issues.apache.org/jira/secure/attachment/12904906/SOLR-11758.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8121", "change_description": ": The UnifiedHighlighter would highlight some terms within some nested\nSpanNearQueries at positions where it should not have.  It's fixed in the UH by\nswitching to the SpanCollector API.  The original Highlighter still has this\nproblem (", "change_title": "UnifiedHighlighter can highlight terms within SpanNear clauses at unmatched positions", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "The UnifiedHighlighter (and original Highlighter) highlight phrases by converting to a SpanQuery and using the Spans start and end positions to assume that every occurrence of the underlying terms between those positions are to be highlighted.  But this is inaccurate; see LUCENE-5455 for a good example, and also LUCENE-2287.  The solution is to use the SpanCollector API which was introduced after the phrase matching aspects of those highlighters were developed.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12905351/LUCENE-2287_UH_SpanCollector.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-2287", "change_description": ": The UnifiedHighlighter would highlight some terms within some nested\nSpanNearQueries at positions where it should not have.  It's fixed in the UH by\nswitching to the SpanCollector API.  The original Highlighter still has this\nproblem (", "change_title": "Unexpected terms are highlighted within nested SpanQuery instances", "detail_type": "Improvement", "detail_affect_versions": "2.9.1", "detail_fix_versions": "7.3", "detail_description": "I haven't yet been able to resolve why I'm seeing spurious highlighting in nested SpanQuery instances.  Briefly, the issue is illustrated by the second instance of \"Lucene\" being highlighted in the test below, when it doesn't satisfy the inner span.  There's been some discussion about this on the java-dev list, and I'm opening this issue now because I have made some initial progress on this. This new test, added to the  HighlighterTest class in lucene_2_9_1, illustrates this: /* String theText = \"The Lucene was made by Doug Cutting and Lucene great Hadoop was\"; // Problem   //String theText = \"The Lucene was made by Doug Cutting and the great Hadoop was\"; // Works okay String fieldName = \"SOME_FIELD_NAME\"; SpanNearQuery spanNear = new SpanNearQuery(new SpanQuery[] , 5, true); Query query = new SpanNearQuery(new SpanQuery[] , 4, true); String expected = \"The <B>Lucene</B> was made by <B>Doug</B> Cutting and Lucene great <B>Hadoop</B> was\";   //String expected = \"The <B>Lucene</B> was made by <B>Doug</B> Cutting and the great <B>Hadoop</B> was\"; String observed = highlightField(query, fieldName, theText);   System.out.println(\"Expected: \\\"\" + expected + \"\\n\" + \"Observed: \\\"\" + observed); assertEquals(\"Why is that second instance of the term \\\"Lucene\\\" highlighted?\", expected, observed); } Is this an issue that's arisen before?  I've been reading through the source to QueryScorer, WeightedSpanTerm, WeightedSpanTermExtractor, Spans, and NearSpansOrdered, but haven't found the solution yet.  Initially, I thought that the extractWeightedSpanTerms method in WeightedSpanTermExtractor should be called on each clause of a SpanNearQuery or SpanOrQuery, but that didn't get me too far.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12437636/LUCENE-2287.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-5455", "change_description": ": The UnifiedHighlighter would highlight some terms within some nested\nSpanNearQueries at positions where it should not have.  It's fixed in the UH by\nswitching to the SpanCollector API.  The original Highlighter still has this\nproblem (", "change_title": "Nested SpanNear queries lose positional highlights", "detail_type": "Bug", "detail_affect_versions": "4.3.1,4.6.1", "detail_fix_versions": "7.3", "detail_description": "Given text of: \"x y z x z x a\" With a query of: spanNear([spanNear([text:x, text:y, text:z], 0, true), text:a], 10, false) Resulting highlight: <B>x</B> <B>y</B> <B>z</B> <B>x</B> <B>z</B> <B>x</B> <B>a</B> Expected highlight: <B>x</B> <B>y</B> <B>z</B> x z x <B>a</B> This is caused because WeightedSpanTermExtractor.extractWeightedSpanTerms takes the SpanQuery and flattens all terms and uses the positions from the outermost SpanNear clause (ignoring the nested SpanNear positions). I believe this could be resolved with a little recursion - walking the span query tree in the extractWeightedSpanTerms method.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12629763/LUCENE-5455-Tests.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6796", "change_description": ": The UnifiedHighlighter would highlight some terms within some nested\nSpanNearQueries at positions where it should not have.  It's fixed in the UH by\nswitching to the SpanCollector API.  The original Highlighter still has this\nproblem (", "change_title": "Some terms incorrectly highlighted in complex SpanQuery", "detail_type": "Bug", "detail_affect_versions": "5.3", "detail_fix_versions": "7.3", "detail_description": "modassar initially raised this on LUCENE-5205.  I'm opening this as a separate issue. If a SpanNear is within a SpanOr, it looks like the child terms within the SpanNear query are getting highlighted even if there is no match on that SpanNear query...in some special cases.  Specifically, in the format of the parser in LUCENE-5205 \"(b [c z]) d\\\"~2\", which is equivalent to: find \"b\" or the phrase \"c z\" within two words of \"d\" either direction This affects trunk.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12755175/LUCENE-6796-testcase.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8120", "change_description": ": Fix LatLonBoundingBox's toString() method", "change_title": "Fix LatLonBoundingBox's toString() method", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "none", "patch_link": "https://issues.apache.org/jira/secure/attachment/12905303/LUCENE-8120.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8130", "change_description": ": Fix NullPointerException from TermStates.toString()", "change_title": "NullPointerException from TermStates.toString()", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "none", "patch_link": "https://issues.apache.org/jira/secure/attachment/12906113/LUCENE-8130.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8124", "change_description": ": Fixed HyphenationCompoundWordTokenFilter to handle correctly\nhyphenation patterns with indicator >= 7.", "change_title": "Hyphenation patterns with indicator >=7 fail", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Hyphenation patterns containing an hyphenation indicator 7, 8 or 9 at an uneven position don't work. This is caused by a wrong bit shifting operation at HyphenationTree.getValue which should read ((v & 0x0f0)>>>4)", "patch_link": "https://issues.apache.org/jira/secure/attachment/12906810/testcase.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8163", "change_description": ": BaseDirectoryTestCase could produce random filenames that fail\non Windows", "change_title": "BaseDirectoryTestCase.testListAllIsSorted() can create Windows-incompatible names", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "This test generates a random set of strings for use as filenames, and then checks that the implementation under test returns them in sorted order from listAll().  However, on Windows there are a number of filenames that are disallowed (generally old-school handle names, eg con, prn, lpt1, etc), so if the test generates one of them, and is being run on Windows, then FileSystemExceptions can be thrown.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12909811/LUCENE-8163.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8174", "change_description": ": Fixed {Float,Double,Int,Long}Range.toString().", "change_title": "ArrayIndexOutOfBoundsException in IntRange.toString and its siblings", "detail_type": "Bug", "detail_affect_versions": "7.2", "detail_fix_versions": "7.3,8.0", "detail_description": "The following code produces an ArrayIndexOutOfBoundsException: IntRange intRange = new IntRange(\"foo\", new int[] { 1 }, new int[] { 2 });         System.out.println(intRange.toString()); The exception is thrown in NumericUtils.sortableBytesToInt, which is fed an incorrect offset. The bug appears to be in IntRange.toString. I guess the for loop should read for (int d=0; d<type.pointDimensionCount()/2; ++d) instead of for (int d=1; d<type.pointDimensionCount(); ++d) because the number of dimensions is half the number of \"point dimensions\" (cf. the checks on the dimension parameter in getMin() and getMax()). The same bug is found in the DoubleRange, FloatRange, and LongRange classes.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12910730/LUCENE-8174.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8182", "change_description": ": Fixed BoostingQuery to apply the context boost instead of the parent query\nboost", "change_title": "BoostingQuery applies the wrong boost to the query score", "detail_type": "Bug", "detail_affect_versions": "7.0,7.1,7.2", "detail_fix_versions": "7.3", "detail_description": "BoostingQuery applies the parent query boost instead of the boost set on the query due to a name clash in the anonymous class created by the createWeight method.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12911413/LUCENE-8182.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Bug Fixes", "change_id": "LUCENE-8188", "change_description": ": Fixed bugs in OpenNLPOpsFactory that were causing InputStreams fetched from the\nResourceLoader to be leaked", "change_title": "OpenNLPOpsFactory leaks filehandles of models", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "I appears that all methods in OpenNLPOpsFactory which use a ResourceLoader to get an InputStream to use for building a model are not closing those InputStreams This doesn't seem to negatively affect any existing lucene/analysis/opennlp tests, because the JVM doesn't know/care that there is a filehandle still open at the end of the test (is there a way to make the test complain?)  but it does seem to cause a Solr level test failure on windows (SOLR-12046) because the solr tests create a temp dir where pre-built models are copied for use, and when the test completes the cleanup attempts to delete those copies of the files but windows won't let it because they are still open. presumably if a lucene/analysis/opennlp test also made a copy of the files a similar failure would be triggered – but only on windows", "patch_link": "https://issues.apache.org/jira/secure/attachment/12912508/LUCENE-8188.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8111", "change_description": ": IndexOrDocValuesQuery Javadoc references outdated method name.", "change_title": "IndexOrDocValuesQuery Javadoc references outdated method name", "detail_type": "Bug", "detail_affect_versions": "7.2,8.0", "detail_fix_versions": "7.3,8.0", "detail_description": "The Javadoc on IndexOrDocValuesQuery references the SortedNumericDocValuesField.newRangeQuery method, which has been renamed SortedNumericDocValuesField.newSlowRangeQuery per LUCENE-7892.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12903962/IndexOrDocValuesQuery.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8106", "change_description": ": Add script (reproduceJenkinsFailures.py) to attempt to reproduce\nfailing tests from a Jenkins log.", "change_title": "Add script to attempt to reproduce failing tests from a Jenkins log", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.4,8.0", "detail_description": "This script will be runnable from a downstream job triggered by an upstream failing Jenkins job, passing log location info between the two. The script will also be runnable manually from a developer's cmdline. From the script help:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12911846/LUCENE-8106-part4.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8075", "change_description": ": Removed unnecessary null check in IntersectTermsEnum.", "change_title": "Possible null pointer dereference in core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java", "detail_type": "Bug", "detail_affect_versions": "7.1", "detail_fix_versions": "7.3,8.0", "detail_description": "Possible null pointer dereference in core/src/java/org/apache/lucene/codecs/blocktree/IntersectTermsEnum.java. at line 119. The fr.index may be NULL. This result is based on static analysis tools and the details are shown below: * * It is not sure if fr.index can be NULL in runtime. We think it is reasonable to fix it by a test if fr.index is NULL and an error handling. -------------- Please Refer to \"Trusted Operating System and System Assurance Working Group, TCA, Institute of Software, Chinese Academy of Sciences\" in the acknowledgement if applicable.", "patch_link": "none", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8156", "change_description": ": Require users to not have ASM on the Ant classpath during build.\nThis is required by", "change_title": "patch-mrjar-classes fails if an old version of ASM is on the Ant classpath", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "If some optional tasks that depend on an old version of ASM are installed, patching fails with the following error: /home/jpountz/src/lucene-solr/lucene/common-build.xml:565: java.lang.IncompatibleClassChangeError: class org.objectweb.asm.commons.ClassRemapper has interface org.objectweb.asm.ClassVisitor as super class The reason is that ClassRemapper is loaded from the right place, but ClassVisitor, its parent class, is loaded from the parent classpath which may be a different version. It is easy to reproduce:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12909274/LUCENE-8156.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-7966", "change_description": ": Require users to not have ASM on the Ant classpath during build.\nThis is required by", "change_title": "build mr-jar and use some java 9 methods if available", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "See background: http://openjdk.java.net/jeps/238 It would be nice to use some of the newer array methods and range checking methods in java 9 for example, without waiting for lucene 10 or something. If we build an MR-jar, we can start migrating our code to use java 9 methods right now, it will use optimized methods from java 9 when thats available, otherwise fall back to java 8 code. This patch adds: It sets these up in org.apache.lucene.future as 1-1 mappings to java methods. This way, we can simply directly replace call sites with java 9 methods when java 9 is a minimum. Simple 1-1 mappings mean also that we only have to worry about testing that our java 8 fallback methods work. I found that many of the current byte array methods today are willy-nilly and very lenient for example, passing invalid offsets at times and relying on compare methods not throwing exceptions, etc. I fixed all the instances in core/codecs but have not looked at the problems with AnalyzingSuggester. Also SimpleText still uses a silly method in ArrayUtil in similar crazy way, have not removed that one yet.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12886960/LUCENE-7966.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8161", "change_description": ": spatial-extras: the Spatial4j dependency has been updated from 0.6 to 0.7,\nwhich is drop-in compatible (Lucene doesn't expressly use any of the few API differences).\nSpatial4j 0.7 is compatible with JTS 1.15.0 and not any prior version.  JTS 1.15.0 is\ndual-licensed to include BSD; prior versions were LGPL.", "change_title": "Update to Spatial4j 0.7 (to support JTS 1.15)", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3", "detail_description": "Spatial4j 0.7 was released late December 2017, principally with support for JTS 1.15.  There are some other changes less pertinent to Lucene/Solr but I'll refer to the change list: https://github.com/locationtech/spatial4j/blob/spatial4j-0.7/CHANGES.md This JTS release has an API breakage in that the package root was changed from com.vividsolutions to org.locationtech but should otherwise be compatible. JTS is now dual-licensed as EPL 1.0 and EDL 1.0 (a BSD style 3-clause license). This JTS release also included various improvements, including faster LineString intersection.  That performance improvement was found in the context of Lucene spatial-extras real-world use. Anyone using JTS with lucene-spatial-extras will be forced to update to JTS 1.15.  I'd like to add a test dependency from lucene-spatial-extras to JTS (the BSD licensed version of course) as there is at least one test with a JUnit \"assumeTrue\" on it being on the classpath – JtsPolygonTest.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12909302/LUCENE-8161_Spatial4j_0_7_and_add_JTS_1_15_0.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8155", "change_description": ": Add back support in smoke tester to run against later Java versions.", "change_title": "Add Java 9 support to smoke tester", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "After adding MR-JAR support with LUCENE-7966, we should test the release candidates with Java 9. Therefore the already existing code in build.xml that uses a separate environment variable to pass JAVA9_HOME should be reenabled. This also requires reconfiguring Jenkins.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12909968/LUCENE-8155.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8169", "change_description": ": Migrated build to use OpenClover 4.2.1 for checking code coverage.", "change_title": "Migrate build to use OpenClover 4.2.1", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Last year, Atlassian opensourced Clover and stopped releasing new versions. Latest supported version is 4.1.2: https://www.atlassian.com/blog/announcements/atlassian-clover-open-source After opensourcing it was foked and OpenClover was founded: http://openclover.org/ The latest OpenClover version is 4.2.1. This will issue will migrate to the opensourced OpenClover 4.2.1 version (also in preparation for Java 9). It will mainly remove the license file and cleans up the build to no longer refer to it.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12910064/LUCENE-8169.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Other", "change_id": "LUCENE-8170", "change_description": ": Improve OpenClover reports (separate test from production code);\nenable coverage reports inside test-frameworks.", "change_title": "Improve OpenClover reports (separate test from production code)", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "Currently the Clover reports mix production and test code. This is due to a misunderstanding (by bad documentation). The testsources in clover-setup are treated different than at reporting time. In clover setup they are only used to figure out where tests could possibly be, but final decision is done on the file name and annotations. All code inside testsources of cloversetup thats not a real test is treated as application class. So we see our test-framework classes and utility classes between our production code in the report. To fix this, the clover-report task must get a fileset (unfortunately, with same name like clover-setup to make it more confusing) that selects all java files which are part of test code (testcases and utility code). Once I figured this out this was easy to fix!", "patch_link": "https://issues.apache.org/jira/secure/attachment/12910123/LUCENE-8170.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Build", "change_id": "LUCENE-8168", "change_description": ": Moved Groovy scripts in build files to separate files.\nUpdate Groovy to 2.4.13.", "change_title": "Refactor build.xml files by moving groovy scripts to separate files", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "After doing LUCENE-7966, I figured out that it is better for syntax highlighting and maintenance to move \"huge\" groovy scripts with complex logic to separate files. This patch moves all except the 3-liner groovy scripts for test setup in our build.xml files to separate scripts in the tools folder. It also updates Groovy to latest version. This change also helps when we will migrate to another build system some time in the future (e.g., Gradle).", "patch_link": "https://issues.apache.org/jira/secure/attachment/12910057/LUCENE-8168.patch", "patch_content": "none"}
{"library_version": "7.3.0", "change_type": "Build", "change_id": "LUCENE-8176", "change_description": ": HttpReplicatorTest awaits more than a minute for stopping Jetty threads", "change_title": "HttpReplicatorTest sometimes fails with leaked thread", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "7.3,8.0", "detail_description": "I can't reproduce it locally when beasting thousands of times but it occurs on the Elastic CI. The logs look like this: This line in particular is interesting: . It means that Jetty waited for 500ms for this thread to finish its work, then interrupted it, then waited again for 500ms and the thread was still alive. It is not clear to me whether the bug is yet. I guess it could be either Jetty or how the test handles InterruptedException.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12912892/LUCENE-8176.patch", "patch_content": "none"}
