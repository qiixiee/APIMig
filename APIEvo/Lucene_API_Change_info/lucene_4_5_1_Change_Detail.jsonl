{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-4998", "change_description": ": Fixed a few places to pass IOContext.READONCE instead\nof IOContext.READ", "change_title": "be more precise about IOContext for reads", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "Set the context as IOContext.READ / IOContext.READONCE where applicable Motivation: Custom PostingsFormat may want to check the context on SegmentReadState and branch differently, but for this to work properly the context has to be specified correctly up the stack. For example, DirectPostingsFormat only loads postings into memory if the context != MERGE. However a better condition would be context == Context.READ && !context.readOnce.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12582943/LUCENE-4998.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5242", "change_description": ": DirectoryTaxonomyWriter.replaceTaxonomy did not fully reset\nits state, which could result in exceptions being thrown, as well as\nincorrect ordinals returned from getParent.", "change_title": "DirectoryTaxonomyWriter.replaceTaxonomy did not fully reset its state", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "If you call DirTaxoWriter.replaceTaxonomy with a larger taxonomy than the current one, you may hit an AIOOBE on the next add category (or getParent) call. I'll attach a testcase + fix shortly.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12604803/LUCENE-5242.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5254", "change_description": ": Fixed bounded memory leak, where objects like live\ndocs bitset were not freed from an starting reader after reopening\nto a new reader and closing the original one.", "change_title": "SegmentCoreReader's \"owner\" reference back to the first SegmentReader causes leaks", "detail_type": "Bug", "detail_affect_versions": "4.6,6.0", "detail_fix_versions": "4.5.1,4.6,5.0", "detail_description": "Spinoff from LUCENE-5248, where Shai discovered this ... SegmentCoreReaders has a SegmentReader owner member, that points to the first SegmentReader that was opened.  When that SR is reopened to SR2, e.g. because new deletes or NDV updates happened, the same SCR is shared. But, even if you close SR1, any thing it points to cannot be GCd because SCR is pointing to it. I think the big things are liveDocs and the NDV update maps; Shai is going to fix the latter in LUCENE-5248, so this issue should fix liveDocs. The simplest fix is to make liveDocs not final and null it out in doClose ... but that's sort of fragile (what if we add other members in the future and forget to null them on close?).  I think it'd be better to eliminate the owner reference; it's only used so we can evict FieldCache entry once the core is closed.  Maybe we can just store the coreCacheKey instead?", "patch_link": "https://issues.apache.org/jira/secure/attachment/12606463/LUCENE-5254.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5262", "change_description": ": Fixed file handle leaks when multiple attempts to open an\nNRT reader hit exceptions.", "change_title": "StandardDirectoryReader should decRef readers on exception, not close them", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "I've hit this while debugging a test, and was able to reproduce with a simple testcase. StandardDirectoryReader.open (nrt) calls IOUtils.close() on hitting an exception from RLD.getReadOnlyClone. But this is wrong, since if two attempts are made to obtain an NRT reader, and both of them fail, the readers that were closed on the first time are no longer closed, since their \"closed\" member is true. It should instead decRef() them. I'll upload a testcase and fix shortly.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12607158/LUCENE-5262.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5263", "change_description": ": Transient IOExceptions, e.g. due to disk full or file\ndescriptor exhaustion, hit at unlucky times inside IndexWriter could\nlead to silently losing deletions.", "change_title": "Deletes may be silently lost if an IOException is hit and later not hit (e.g., disk fills up and then frees up)", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "This case is tricky to handle, yet I think realistic: disk fills up temporarily, causes an exception in writeLiveDocs, and then the app keeps using the IW instance. Meanwhile disk later frees up again, IW is closed \"successfully\".  In certain cases, we can silently lose deletes in this case. I had already committed TestIndexWriterDeletes.testNoLostDeletesOnDiskFull, and Jenkins seems happy with it so far, but when I added fangs to the test (cutover to RandomIndexWriter from IndexWriter, allow IOE during getReader, add randomness to when exc is thrown, etc.), it uncovered some real/nasty bugs: should instead be", "patch_link": "https://issues.apache.org/jira/secure/attachment/12607351/LUCENE-5263.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5264", "change_description": ": CommonTermsQuery ignored minMustMatch if only high-frequent\nterms were present in the query and the high-frequent operator was set\nto SHOULD.", "change_title": "CommonTermsQuery ignores minMustMatch if only high freq terms are present.", "detail_type": "Bug", "detail_affect_versions": "4.5,6.0", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "if we only have high freq terms we move to a pure conjunction and ignore the min must match entirely if it is > 0.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12607356/LUCENE-5264.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5269", "change_description": ": Fix bug in NGramTokenFilter where it would sometimes count\nunicode characters incorrectly.", "change_title": "TestRandomChains failure", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.5.1,4.6,6.0", "detail_description": "One of EdgeNGramTokenizer, ShingleFilter, NGramTokenFilter is buggy, or possibly only the combination of them conspiring together.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12607709/LUCENE-5269.patch", "patch_content": "none"}
{"library_version": "4.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-5289", "change_description": ": IndexWriter.hasUncommittedChanges was returning false\nwhen there were buffered delete-by-Term.", "change_title": "IndexWriter.hasUncommittedChanges() returns false if there are pending delete by term only", "detail_type": "Bug", "detail_affect_versions": "4.4", "detail_fix_versions": "4.5.1,6.0", "detail_description": "If there are only delete by term and no document adds, then IndexWriter.hasUncommittedChanges() returns false. http://lucene.472066.n3.nabble.com/Solr-4-4-Master-Slave-configuration-Replication-Issue-with-Commits-after-deleting-documents-using-DeD-td4094158.html", "patch_link": "https://issues.apache.org/jira/secure/attachment/12608910/LUCENE-5289.patch", "patch_content": "none"}
