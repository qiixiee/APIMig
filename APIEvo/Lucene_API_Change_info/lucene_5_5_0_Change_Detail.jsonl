{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-5868", "change_description": ": JoinUtil.createJoinQuery(..,NumericType,..) query-time join\nfor LONG and INT fields with NUMERIC and SORTED_NUMERIC doc values.", "change_title": "JoinUtil support for NUMERIC docValues fields", "detail_type": "New Feature", "detail_affect_versions": "None", "detail_fix_versions": "5.5", "detail_description": "while polishing SOLR-6234 I found that JoinUtil can't join int dv fields at least.  I plan to provide test/patch. It might be important, because Solr's join can do that. Please vote if you care!", "patch_link": "https://issues.apache.org/jira/secure/attachment/12774720/LUCENE-5868-lambdarefactoring.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6939", "change_description": ": Add exponential reciprocal scoring to\nBlendedInfixSuggester, to even more strongly favor suggestions that\nmatch closer to the beginning", "change_title": "BlendedInfixSuggester to support exponential reciprocal BlenderType", "detail_type": "Improvement", "detail_affect_versions": "5.4", "detail_fix_versions": "5.5,6.0", "detail_description": "The orignal BlendedInfixSuggester introduced in LUCENE-5354 has support for: These are used to score documents based on the position of the matched token i.e the closer is the matched term to the beginning, the higher score you get. In some use cases, we need a more aggressive scoring based on the position. That's where the exponential reciprocal comes into play  i.e  coef = 1/Math.pow(position+1, exponent) where the exponent is a configurable variable.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12778927/LUCENE-6939.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6958", "change_description": ": Improved CustomAnalyzer to take class references to factories\nas alternative to their SPI name. This enables compile-time safety when\ndefining analyzer's components.", "change_title": "Improve CustomAnalyzer to also allow to specify factory directly (for compile-time safety)", "detail_type": "Improvement", "detail_affect_versions": "5.4", "detail_fix_versions": "5.5,6.0", "detail_description": "Currently CustomAnalyzer only allows to specify the SPI names of factories. As the fluent builder pattern is mostly used inside Java code, it is better for type safety to optionally also specify the factory class directly (using compile-time safe patterns like .withTokenizer(WhitespaceTokenizerFactory.class)). With the string names, you get the error only at runtime. Of course this does not help with wrong, spelled parameter names, but it also has the side effect that you can click on the class name in your code to get javadocs with the parameter names. This issue will add this functionality and update the docs/example. Thanks to shaie for suggesting this!", "patch_link": "https://issues.apache.org/jira/secure/attachment/12780498/LUCENE-6958.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6818", "change_description": ",", "change_title": "Implementing Divergence from Independence (DFI) Term-Weighting for Lucene/Solr", "detail_type": "New Feature", "detail_affect_versions": "5.3", "detail_fix_versions": "5.5,6.0", "detail_description": "As explained in the write-up, many state-of-the-art ranking model implementations are added to Apache Lucene. This issue aims to include DFI model, which is the non-parametric counterpart of the Divergence from Randomness (DFR) framework. DFI is both parameter-free and non-parametric: It is highly recommended not to remove stopwords (very common terms: the, of, and, to, a, in, for, is, on, that, etc) with this similarity. For more information see: A nonparametric term weighting method for information retrieval based on measuring the divergence from independence", "patch_link": "https://issues.apache.org/jira/secure/attachment/12771353/LUCENE-6818.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6986", "change_description": ",", "change_title": "Add more DFI independence measures", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Since LUCENE-6818 we have DFISimilarity which implements normalized chi-squared distance. But there are other alternatives (as described in http://trec.nist.gov/pubs/trec21/papers/irra.web.nb.pdf): I think we should just provide the three independence measures, and let the user choose. Similar to how we do DFR/IB/etc.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783524/LUCENE-6986.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "SOLR-4619", "change_description": ": Added removeAllAttributes() to AttributeSource, which removes\nall previously added attributes.", "change_title": "Improve PreAnalyzedField query analysis", "detail_type": "Bug", "detail_affect_versions": "4.0,4.1,4.2,4.2.1,6.0", "detail_fix_versions": "5.5,6.0", "detail_description": "PreAnalyzed field extends plain FieldType and mistakenly uses the DefaultAnalyzer as query analyzer, and doesn't allow for customization via <analyzer> schema elements. Instead it should extend TextField and support all query analysis supported by that type.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783243/SOLR-4619.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-7010", "change_description": ": Added MergePolicyWrapper to allow easy wrapping of other policies.", "change_title": "Create MergePolicyWrapper", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "trunk,5.5", "detail_description": "We currently have two MergePolicy implementations that are wrappers around another MP: SortingMergePolicy and UpgradeIndexMergePolicy. A MergePolicyWrapper will simplify building additional such wrapping MPs by delegating all method calls to the wrapped instance, and allowing implementations to override only what they need. Also, this issue removes the final modifier from MP public methods so that they can be delegated properly. See LUCENE-7008 for a test failure that uncovered this issue.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12786011/LUCENE-7010.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6997", "change_description": ": refactor sandboxed GeoPointField and query classes to lucene-spatial\nmodule under new lucene.spatial.geopoint package", "change_title": "Graduate GeoUtils and postings based GeoPointField from sandbox...", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "trunk,5.5", "detail_description": "GeoPointField is a lightweight dependency-free postings based geo field currently in sandbox. It has evolved into a very fast lightweight geo option that heavily leverages the optimized performance of the postings structure. It was originally intended to graduate to core but this does not seem appropriate given the variety of \"built on postings\" term encoding options (e.g., see LUCENE-6930). Additionally, the Geo*Utils classes are dependency free lightweight relational approximation utilities used by both GeoPointField and the BKD based LatLonField and can also be applied to benefit the lucene-spatial module. These classes have been evolving and baking for some time and are at a maturity level qualifying for promotion from sandbox. This will allow support for experimental encoding methods with (minimal) backwards compatibility - something sandbox does not allow. Since GeoPoint classes are dependency free, all GeoPointField and support and utility classes currently in sandbox would be promoted to the spatial3d package. (possibly a separate issue to rename spatial3d to spatialcore or spatiallite?) Such that for basic lightweight Geo support one would only need a handful of lucene jars. By simply adding the lucene-spatial module and its dependency jars users can obtain more advanced geospatial support (heatmap facets, full shape relations, etc).", "patch_link": "https://issues.apache.org/jira/secure/attachment/12787146/LUCENE-6997.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6908", "change_description": ": GeoUtils static relational methods have been refactored to new\nGeoRelationUtils and now correctly handle large irregular rectangles, and\npole crossing distance queries.", "change_title": "TestGeoUtils.testGeoRelations is buggy with irregular rectangles", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "None", "detail_description": "The .testGeoRelations method doesn't exactly test the behavior of GeoPoint*Query as its using the BKD split technique (instead of quad cell division) to divide the space on each pass. For \"large\" distance queries this can create a lot of irregular rectangles producing large radial distortion error when using the cartesian approximation methods provided by GeoUtils. This issue improves the accuracy of GeoUtils cartesian approximation methods on irregular rectangles without having to cut over to an expensive oblate geometry approach.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779703/LUCENE-6908.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6900", "change_description": ": Grouping sortWithinGroup variables used to allow null to mean\nSort.RELEVANCE.  Null is no longer permitted.", "change_title": "Grouping sortWithinGroup should use Sort.RELEVANCE to indicate that, not null", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5", "detail_description": "In AbstractSecondPassGroupingCollector, withinGroupSort uses a value of null to indicate a relevance sort.  I think it's nicer to use Sort.RELEVANCE for this â€“ after all it's how the groupSort variable is handled.  This choice is also seen in GroupingSearch; likely some other collaborators too. martijn.v.groningen is there some wisdom in the current choice that escapes me?  If not I'll post a patch.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12774159/LUCENE_6900.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6919", "change_description": ": The Scorer class has been refactored to expose an iterator\ninstead of extending DocIdSetIterator. asTwoPhaseIterator() has been renamed\nto twoPhaseIterator() for consistency.", "change_title": "Change the Scorer API to expose an iterator instead of extending DocIdSetIterator", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "I was working on trying to address the performance regression on LUCENE-6815 but this is hard to do without introducing specialization of DisjunctionScorer which I'd like to avoid at all costs. I think the performance regression would be easy to address without specialization if Scorers were changed to return an iterator instead of extending DocIdSetIterator. So conceptually the API would move from to This would help me because then if none of the sub clauses support two-phase iteration, DisjunctionScorer could directly return the approximation as an iterator instead of having to check if twoPhase == null at every iteration. Such an approach could also help remove some method calls. For instance TermScorer.nextDoc calls PostingsEnum.nextDoc but with this change TermScorer.iterator() could return the PostingsEnum and TermScorer would not even appear in stack traces when scoring. I hacked a patch to see how much that would help and luceneutil seems to like the change:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12776598/LUCENE-6919.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6973", "change_description": ": TeeSinkTokenFilter no longer accepts a SinkFilter (the latter\nhas been removed). If you wish to filter the sinks, you can wrap them with\nany other TokenFilter (e.g. a FilteringTokenFilter). Also, you can no longer\nadd a SinkTokenStream to an existing TeeSinkTokenFilter. If you need to\nshare multiple streams with a single sink, chain them with multiple\nTeeSinkTokenFilters.\nDateRecognizerSinkFilter was renamed to DateRecognizerFilter and moved under\nanalysis/common. TokenTypeSinkFilter was removed (use TypeTokenFilter instead).\nTokenRangeSinkFilter was removed.", "change_title": "Improve TeeSinkTokenFilter", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "TeeSinkTokenFilter can be improved in several ways, as it's written today: The most major one is removing SinkFilter which just doesn't work and is confusing. E.g., if you set a SinkFilter which filters tokens, the attributes on the stream such as PositionIncrementAttribute are not updated. Also, if you update any attribute on the stream, you affect other SinkStreams ... It's best if we remove this confusing class, and let consumers reuse existing TokenFilters by chaining them to the sink stream. After we do that, we can make all the cached states a single (immutable) list, which is shared between all the sink streams, so we don't need to keep many references around, and also deal with WeakReference. Besides that there are some other minor improvements to the code that will come after we clean up this class. From a backwards-compatibility standpoint, I don't think that SinkFilter is actually used anywhere (since it just ... confusing and doesn't work as expected), and therefore I believe it won't affect anyone. If however someone did implement a SinkFilter, it should be trivial to convert it to a TokenFilter and chain it to the SinkStream.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12782501/LUCENE-6973.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6980", "change_description": ": Default applyAllDeletes to true when opening\nnear-real-time readers", "change_title": "Default to applying deletes when opening NRT reader from writer", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "6.0", "detail_description": "Today, DirectoryReader.open, etc., all require you to pass a supremely expert boolean applyDeletes.  I think the vast majority of users should just default this to true.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12782787/LUCENE-6980.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6981", "change_description": ": SpanQuery.getTermContexts() helper methods are now public, and\nSpanScorer has a public getSpans() method.", "change_title": "SpanQuery.getTermContexts() static helper methods should be public", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5", "detail_description": "Currently, SpanQuery has two protected static helper methods for extracting all TermContext objects from a collection of SpanWeights.  These are useful for objects extending SpanQuery.  However, because they're static protected, they can't be accessed by subclasses if those subclasses have been loaded by a different classloader (for example, if they're being loaded as a Solr plugin).", "patch_link": "https://issues.apache.org/jira/secure/attachment/12782847/LUCENE-6981.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6932", "change_description": ": IndexInput.seek implementations now throw EOFException\nif you seek beyond the end of the file", "change_title": "Seek past EOF with RAMDirectory should throw EOFException", "detail_type": "Bug", "detail_affect_versions": "6.0", "detail_fix_versions": "5.4.2,6.0", "detail_description": "In the JUnit test case from the attached file, I call \"IndexInput.seek()\" on a position past EOF. However, there is no EOFException that is thrown. To reproduce the error, please use the seed test: -Dtests.seed=8273A81C129D35E2", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783600/LUCENE-6932.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6988", "change_description": ": IndexableField.tokenStream() no longer throws IOException", "change_title": "IndexableField.tokenStream() doesn't need to throw IOException", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "No implementations actually throw IOException, and in general TokenStream construction doesn't use IO, only consumption.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783830/LUCENE-6988.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-7028", "change_description": ": Deprecate a duplicate method in NumericUtils.", "change_title": "Remove useless clone of method in Lucene 6' LegacyNumericUtils", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "6.0", "detail_description": "While working on LUCENE-7027 I noticed, that NumericUtils contains the same method 2 times (same signature), one just delegating to the other. I will remove the duplicate for 6.0.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12787821/LUCENE-7028.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6930", "change_description": ": Decouple GeoPointField from NumericType by using a custom\nand efficient GeoPointTokenStream and TermEnum designed for GeoPoint prefix\nterms.", "change_title": "Decouple GeoPointField from NumericType", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "trunk,5.5", "detail_description": "GeoPointField currently relies on NumericTokenStream to create prefix terms for a GeoPoint using the precision step defined in GeoPointField. At search time GeoPointTermsEnum recurses to a max precision that is computed by the Query parameters. This max precision is never the full precision, so creating and indexing the full precision terms is useless and wasteful (it was always a side effect of just using indexing logic from the Numeric type). Furthermore, since the numerical logic always stored high precision terms first, the recursion in GeoPointTermsEnum required transient memory for storing ranges. By moving the trie logic to its own GeoPointTokenStream and reversing the term order (such that lower resolution terms are first), the GeoPointTermsEnum can naturally traverse, enabling on-demand creation of PrefixTerms. This will be done in a separate issue.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12785007/LUCENE-6930.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6951", "change_description": ": Improve GeoPointInPolygonQuery using point orientation based\nline crossing algorithm, and adding result for multi-value docs when least\n1 point satisfies polygon criteria.", "change_title": "GeoPointInPolygonQuery can be improved", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "None", "detail_description": "GeoRelationutils uses a basic algebraic approach for computing if (and where) a rectangle crosses a polygon by checking the line segments of both the polygon and rectangle. The current suboptimal line crossing approach can be greatly improved by exploiting the orientation of the lines and endpoints. If the endpoints of one line are on different \"sides\" of the line segment then  the two may cross.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779804/LUCENE-6951.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6889", "change_description": ": BooleanQuery.rewrite now performs some query optimization, in\nparticular to rewrite queries that look like: \"+*:* #filter\" to a\n\"ConstantScore(filter)\".", "change_title": "BooleanQuery.rewrite could easily optimize some simple cases", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Follow-up of SOLR-8251: APIs and user interfaces sometimes encourage to write BooleanQuery instances that are not optimal, for instance a typical case that happens often with Solr/Elasticsearch is to send a request that has a MatchAllDocsQuery as a query and some filter, which could be executed more efficiently by directly wrapping the filter into a ConstantScoreQuery. Here are some ideas of rewrite operations that BooleanQuery could perform:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12772541/LUCENE-6889.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6912", "change_description": ": Grouping's Collectors now calculate a response to needsScores()\ninstead of always 'true'.", "change_title": "Grouping's Collectors should have smart needsScores()", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5", "detail_description": "The Grouping module has numerous Collector implementations, and only a couple perhaps override needsScore() with an optimal choice.  Lets do this for all of them.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12774708/LUCENE_6912.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6815", "change_description": ": DisjunctionScorer now advances two-phased iterators lazily,\nstopping to evaluate them as soon as a single one matches. The other iterators\nwill be confirmed lazily when computing score() or freq().", "change_title": "Should DisjunctionScorer advance more lazily?", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Today if you call DisjunctionScorer.advance(X), it will try to advance all sub scorers to X. However, if DisjunctionScorer is being intersected with another scorer (which is almost always the case as we use BooleanScorer for top-level disjunctions), we could stop as soon as we find one matching sub scorer, and only advance the remaining sub scorers when freq() or score() is called.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12776865/LUCENE-6815.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6926", "change_description": ": MUST_NOT clauses now use the match cost API to run the slow bits\nlast whenever possible.", "change_title": "Take matchCost into account for MUST_NOT clauses", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "ReqExclScorer potentially has two TwoPhaseIterators to check: the one for the positive clause and the one for the negative clause. It should leverage the match cost API to check the least costly one first.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12777448/LUCENE-6926.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6944", "change_description": ": BooleanWeight no longer creates sub-scorers if BS1 is not\napplicable.", "change_title": "BooleanWeight.bulkScorer should not build any sub bulk scorer if there are required/prohibited clauses", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "BooleanWeight.bulkScorer creates a sub bulk scorer for all clauses until it meets a clause that is not optional (the only kind of clause it can deal with). However the Weight.bulkScorer method is sometimes costly, so BooleanWeight.bulkScorer should first inspect all clauses to see if any of them is not optional to avoid creating costly bulk scorers to only trash them later.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12778839/LUCENE-6944.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6940", "change_description": ": MUST_NOT clauses execute faster, especially when they are sparse.", "change_title": "Bulk scoring could speed up MUST_NOT clauses", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Today when you have MUST_NOT clauses, the ReqExclScorer is used and needs to check the excluded clauses on every iteration. I suspect we could speed things up by having a BulkScorer that would advance the excluded clause first and then tell the required clause to bulk score up to the next excluded document.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779320/LUCENE-6940.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6470", "change_description": ": Improve efficiency of TermsQuery constructors.", "change_title": "make all TermsQuery ctors efficient", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Currently you have to read the source code to know which ctors will or won't create tons of Term objects... and I know people just love to abuse this query in that way.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12731155/LUCENE-6470.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6976", "change_description": ": BytesRefTermAttributeImpl.copyTo NPE'ed if BytesRef was null.\nAdded equals & hashCode, and a new test for these things.", "change_title": "BytesTermAttributeImpl.copyTo NPEs when the BytesRef is null", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.2,5.5", "detail_description": "The BytesTermAttributeImpl class, not used much I think, has a problem in its copyTo method in which it assumes \"bytes\" isn't null since it calls BytesRef.deepCopyOf on it.  Perhaps deepCopyOf should support null?  And also, toString(), equals() and hashCode() aren't implemented but we can do so. This was discovered in SOLR-8541; the spatial PrefixTreeStrategy uses this attribute and the CachingTokenFilter when used on the analysis chain will call clearAttributes() in it's end() method and then capture the state so it can be replayed later.  BytesTermAttributeImpl.clear() nulls out the bytes reference.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12782458/LUCENE_6976.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6932", "change_description": ": RAMDirectory's IndexInput was failing to throw\nEOFException in some cases", "change_title": "Seek past EOF with RAMDirectory should throw EOFException", "detail_type": "Bug", "detail_affect_versions": "6.0", "detail_fix_versions": "5.4.2,6.0", "detail_description": "In the JUnit test case from the attached file, I call \"IndexInput.seek()\" on a position past EOF. However, there is no EOFException that is thrown. To reproduce the error, please use the seed test: -Dtests.seed=8273A81C129D35E2", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783600/LUCENE-6932.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6896", "change_description": ": Don't treat the smallest possible norm value as an infinitely\nlong document in SimilarityBase or BM25Similarity. Add more warnings to sims\nthat will not work well with extreme tf values.", "change_title": "Fix/document various Similarity bugs around extreme norm values", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Spinoff from LUCENE-6818: iorixxx found problems with every Similarity (except ClassicSimilarity) when trying to test how they behave on every possible norm value, to ensure they are robust for all index-time boosts. There are several problems: 1. buggy normalization decode that causes the smallest possible norm value (0) to be treated as an infinitely long document. These values are intended to be encoded as non-negative finite values, but going to infinity breaks everything. 2. various problems in the less practical functions that already have documented warnings that they do bad things for extreme values. These impact DFR models D, Be, and P and IB distribution SPL.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12772406/LUCENE-6896.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6984", "change_description": ": SpanMultiTermQueryWrapper no longer modifies its wrapped query.", "change_title": "MultiTermQuery mutability can cause assertion failures in BooleanQuery", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "BooleanQuery caches its hashcode on the grounds that it is immutable.  However, this immutability doesn't hold if some of its clauses hold queries that are not themselves immutable - for example, a MultiTermQuery with a changeable rewrite method.  If one of these clauses is mutated after the hashcode has been calculated, then the next time the parent BooleanQuery is used the assertion in BooleanQuery.hashCode() will fail.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783335/LUCENE-6984.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6998", "change_description": ": Fix a couple places to better detect truncated index files\nas corruption.", "change_title": "We should detect truncation for all index files", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.4.2,5.5,6.0", "detail_description": "rcmuir noticed that Lucene60PointReader does not detect truncation of its data file on reader init ... so I added a test to catch this, confirmed it caught the bug, and fixed the bug, and fixed a couple other things uncovered by the test. I also improved the other TestAllFiles* tests to use LineFileDocs so they index points, and it caught another bug in Lucene60PointFormat (using the same codec name in two files). There is more to do here, e.g. we also need a test that catches places where we fail to check the index header on init, which was also missing for Lucene60PointReader.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12784871/LUCENE-6998.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7002", "change_description": ": Fixed MultiCollector to not throw a NPE if setScorer is called\nafter one of the sub collectors is done collecting.", "change_title": "MultiCollector throws NPE when there is CollectTerminatedException is thrown by a subcollector", "detail_type": "Bug", "detail_affect_versions": "5.4", "detail_fix_versions": "5.4.2,5.5", "detail_description": "I am seeing this in our log: Looks like is called on line 176, the loop: in setScorer can still step on it, on line 155. I am however, unable to reproduce that with a unit test. I made a copy of this class and added a null check in setScorer() and the problem goes away.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12786809/LUCENE-7002.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7027", "change_description": ": Fixed NumericTermAttribute to not throw IllegalArgumentException\nafter NumericTokenStream was exhausted.", "change_title": "NumericTermAttribute throws IAE after NumericTokenStream is exhausted", "detail_type": "Bug", "detail_affect_versions": "5.5,6.0", "detail_fix_versions": "5.5,6.0", "detail_description": "This small test: hits this unexpected exception: because CachingTokenFilter expects that it can captureState after calling end but NumericTokenStream gets angry about this.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12787799/LUCENE-7027-master.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7018", "change_description": ": Fix GeoPointTermQueryConstantScoreWrapper to add document on\nfirst GeoPointField match.", "change_title": "GeoPoint queries on multi-valued GeoPointField documents can be slow", "detail_type": "Bug", "detail_affect_versions": "5.4,5.4.1", "detail_fix_versions": "5.4.2", "detail_description": "In 5.4/5.4.1 a known bug remains for GeoPoint queries. When filtering over docvalues for a multi-valued document all values were checked regardless of an existing match. This performance bug was fixed in LUCENE-6951 and needs to be back ported to 5.4.", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7019", "change_description": ": Add two-phase iteration to GeoPointTermQueryConstantScoreWrapper.", "change_title": "explore two-phase iteration for GeoPoint query", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "This query today uses an approximation+confirm approach, but it all happens when you call scorer(), in a termsEnum loop. This causes several problems (even after https://issues.apache.org/jira/browse/LUCENE-7018) because it can do too much work, if queries have multiple values since the doc can be \"confirmed\" more than once. I think it would be better to delay this confirmation as much as possible, so that other parts of the query (e.g. other filters, conjunctions, etc) can eliminate checks as well.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12787063/LUCENE-7019.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6989", "change_description": ": Improve MMapDirectory's unmapping checks to catch more non-working\ncases. The unmap-hack does not yet work with recent Java 9. Official support\nwill come with Lucene 6.", "change_title": "Implement MMapDirectory unmapping for coming Java 9 changes", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.5.4,6.0,6.4", "detail_description": "Originally, the sun.misc.Cleaner interface was declared as \"critical API\" in JEP 260 Unfortunately the decission was changed in favor of a oficially supported java.lang.ref.Cleaner API. A side effect of this change is to move all existing sun.misc.Cleaner APIs into a non-exported package. This causes our forceful unmapping to no longer work, because we can get the cleaner instance via reflection, but trying to invoke it will throw one of the new Jigsaw RuntimeException because it is completely inaccessible. This will make our forceful unmapping fail. There are also no changes in Garbage collector, the problem still exists. For more information see this mailing list thread. This commit will likely be done, making our unmapping efforts no longer working. Alan Bateman is aware of this issue and will open a new issue at OpenJDK to allow forceful unmapping without using the now private sun.misc.Cleaner. The idea is to let the internal class sun.misc.Cleaner implement the Runable interface, so we can simply cast to runable and call the run() method to unmap. The code would then work. This will lead to minor changes in our unmapper in MMapDirectory: An instanceof check and casting if possible. I opened this issue to keep track and implement the changes as soon as possible, so people will have working unmapping when java 9 comes out. Current Lucene versions will no longer work with Java 9.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12844298/LUCENE-6989-v3-testFixes.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6924", "change_description": ": Upgrade randomizedtesting to 2.3.2.", "change_title": "Upgrade randomizedtesting to 2.3.2", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "https://github.com/randomizedtesting/randomizedtesting/releases/tag/release%2F2.3.2", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6920", "change_description": ": Improve custom function checks in expressions module\nto use MethodHandles and work without extra security privileges.", "change_title": "Simplify callable function checks in Expression module", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "The expressions module allows to specify custom functions. It does some checks to ensure that the compiled Expression works correctly and does not produce linkage errors. It also checks parameters and return type to  be doubles. There are two problems with the current approach: This issue will use MethodHandles to do the accessibility checks (it uses MethodHandles.publicLookup() to resolve the given reflected method). If that fails, our compiled code cannot acess it. If module system prevents access, this is also checked. To fix the issue with classloaders, it uses a trick: It calls Class.forName() with the classloader we use to compile our expression. If that does not return the same class as the declared method, it also fails compilation. This prevents NoClassDefFoundException on executing the expression. All tests pass.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12775930/LUCENE-6920.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6921", "change_description": ": Fix SPIClassIterator#isParentClassLoader to don't\nrequire extra permissions.", "change_title": "Fix SPIClassIterator#isParentClassLoader to don't require extra permissions", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "This is not really a big issue, because most setups use a \"good\" context classloader. The context classloader is required by the Java ServiceProvider standard to look for META-INF classes. To work around issues in some setups, the analysis and codec SPIs also scan our own classloader, if it is not a parent of the context one. This check requires permissions, if we are not a parent. This will fix the parent check to simply return false (and enforce classpath rescan) if we don't have enough permissions. This is the right thing to do, because if we have no permissions, we are also not a parent!", "patch_link": "https://issues.apache.org/jira/secure/attachment/12775935/LUCENE-6921-fix.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6923", "change_description": ": Fix RamUsageEstimator to access private fields inside\nAccessController block for computing size.", "change_title": "Fix RamUsageEstimator's access to private fields", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "many classes have in their clinit something like: This does inspection of private fields to compute the size, but requires RuntimePermission(\"accessDeclaredMembers\").", "patch_link": "https://issues.apache.org/jira/secure/attachment/12775938/LUCENE-6923.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6907", "change_description": ": make TestParser extendable, rename test/.../xml/\nNumericRangeQueryQuery.xml to NumericRangeQuery.xml", "change_title": "make TestParser extendable", "detail_type": "Test", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Tests for the xml query parser in SOLR-839 for example could then be extending the TestParser class.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12773867/LUCENE-6907.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6925", "change_description": ": add ForceMergePolicy class in test-framework", "change_title": "add (test-framework) [Random]ForceMergePolicy classes", "detail_type": "Test", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "lucene changes: solr changes: motivation:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12776100/LUCENE-6925.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6945", "change_description": ": factor out TestCorePlus(Queries|Extensions)Parser from\nTestParser, rename TestParser to TestCoreParser", "change_title": "factor out TestCorePlus(Queries|Extensions)Parser from TestParser, rename TestParser to TestCoreParser", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Tests for the xml query parser in SOLR-839 for example could then be extending the TestParser or TestCorePlusQueriesParser or TestCorePlusExtensionsParser depending on requirements.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12778856/LUCENE-6945.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6949", "change_description": ": fix (potential) resource leak in SynonymFilterFactory\n(", "change_title": "fix (potential) resource leak in SynonymFilterFactory (coverity CID 120656)", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "https://scan.coverity.com/projects/5620 mentioned on the dev mailing list (http://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3cCAFTwexg51-jm_6MDEoz1rEagN3xgkBeTOz5OU_f+mELbOO1POw@mail.gmail.com%3e) in July 2015.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12779457/LUCENE-6949.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "https://scan.coverity.com/projects/5620", "change_description": ": fix (potential) resource leak in SynonymFilterFactory\n(", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6961", "change_description": ": Improve Exception handling in AnalysisFactories /\nAnalysisSPILoader: Don't wrap exceptions occuring in factory's\nctor inside InvocationTargetException.", "change_title": "Improve Exception handling in AnalysisFactory/SPI loader", "detail_type": "Improvement", "detail_affect_versions": "5.4", "detail_fix_versions": "5.5,6.0", "detail_description": "Currently the AnalysisSPILoader used by AbstractAnalysisFactory uses a catch Exception block when invoking the constructor. If the constructor throws stuff like IllegalArgumentExceptions or similar, this is hidden inside InvocationTargetException, which gets wrapped in IllegalArgumentException. This is not useful. This patch will: This patch will be required by next version of LUCENE-6958.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12780444/LUCENE-6961.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6965", "change_description": ": Expression's JavascriptCompiler now throw ParseException\nwith bad function names or bad arity instead of IllegalArgumentException.", "change_title": "Expression's JavascriptCompiler to throw ParseExceptions with bad function names or arity", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Currently JavascriptCompiler will throw IllegalArgumentException for bad function names (or functions that don't exist) and for bad arity. I can see why this was done this way, but I believe ParseException would also be correct and it would be better since that's the exception clients will be prepared to receive.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12781091/LUCENE-6965-2.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6964", "change_description": ": String-based signatures in JavascriptCompiler replaced\nwith better compile-time-checked MethodType; generated class files\nare no longer marked as synthetic.", "change_title": "Small changes in expressions module", "detail_type": "Improvement", "detail_affect_versions": "5.4", "detail_fix_versions": "5.5,6.0", "detail_description": "This patch is not really worth an issue, but it has 2 small changes in expression's JavaScriptCompiler:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12780851/LUCENE-6964.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6978", "change_description": ": Refactor several code places that lookup locales\nby string name to use BCP47 locale tag instead. LuceneTestCase\nnow also prints locales on failing tests this way.\nLocale#forLanguageTag() and Locale#toString() were placed on list\nof forbidden signatures.", "change_title": "Make LuceneTestCase use language tags instead of parsing locales by hand", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "Since we are on Java 7, the JDK supports standardized language tags as identifiers for Locales. Previous versions of JDK were missing a constructor from Locale#toString() back to a locale, so we had our own, which was broken several times after the JDK changed their Locale internals. This patch will do the following: I would also like to place Locale#forLanguageTag on the forbidden list and disallow directly calling Locale#toString(), the latter is legacy API (according to Java 7 Javadocs). This would fail code that calls toString() directly, e.g. when formatting stuff like \"my Locale: \" + locale. Of course we cannot catch all bad uses.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12782635/LUCENE-6978-5x.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6988", "change_description": ": You can now add IndexableFields directly to a MemoryIndex,\nand create a MemoryIndex from a lucene Document.", "change_title": "IndexableField.tokenStream() doesn't need to throw IOException", "detail_type": "Improvement", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "No implementations actually throw IOException, and in general TokenStream construction doesn't use IO, only consumption.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12783830/LUCENE-6988.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-7005", "change_description": ": TieredMergePolicy tweaks (>= vs. >, @see get vs. set)", "change_title": "TieredMergePolicy tweaks (>= vs. >, @see get vs. set)", "detail_type": "Task", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "and", "patch_link": "https://issues.apache.org/jira/secure/attachment/12785547/LUCENE-7005.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-7006", "change_description": ": increase BaseMergePolicyTestCase use (TestNoMergePolicy and\nTestSortingMergePolicy now extend it, TestUpgradeIndexMergePolicy added)", "change_title": "increase BaseMergePolicyTestCase use", "detail_type": "Test", "detail_affect_versions": "None", "detail_fix_versions": "5.5,6.0", "detail_description": "none", "patch_link": "https://issues.apache.org/jira/secure/attachment/12785548/LUCENE-7006.patch", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-5868", "change_description": ": JoinUtil.createJoinQuery(..,NumericType,..) query-time join\nfor LONG and INT fields with NUMERIC and SORTED_NUMERIC doc values.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6939", "change_description": ": Add exponential reciprocal scoring to\nBlendedInfixSuggester, to even more strongly favor suggestions that\nmatch closer to the beginning", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6958", "change_description": ": Improved CustomAnalyzer to take class references to factories\nas alternative to their SPI name. This enables compile-time safety when\ndefining analyzer's components.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6818", "change_description": ",", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-6986", "change_description": ",", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "SOLR-4619", "change_description": ": Added removeAllAttributes() to AttributeSource, which removes\nall previously added attributes.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "New Features", "change_id": "LUCENE-7010", "change_description": ": Added MergePolicyWrapper to allow easy wrapping of other policies.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6997", "change_description": ": refactor sandboxed GeoPointField and query classes to lucene-spatial\nmodule under new lucene.spatial.geopoint package", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6908", "change_description": ": GeoUtils static relational methods have been refactored to new\nGeoRelationUtils and now correctly handle large irregular rectangles, and\npole crossing distance queries.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6900", "change_description": ": Grouping sortWithinGroup variables used to allow null to mean\nSort.RELEVANCE.  Null is no longer permitted.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6919", "change_description": ": The Scorer class has been refactored to expose an iterator\ninstead of extending DocIdSetIterator. asTwoPhaseIterator() has been renamed\nto twoPhaseIterator() for consistency.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6973", "change_description": ": TeeSinkTokenFilter no longer accepts a SinkFilter (the latter\nhas been removed). If you wish to filter the sinks, you can wrap them with\nany other TokenFilter (e.g. a FilteringTokenFilter). Also, you can no longer\nadd a SinkTokenStream to an existing TeeSinkTokenFilter. If you need to\nshare multiple streams with a single sink, chain them with multiple\nTeeSinkTokenFilters.\nDateRecognizerSinkFilter was renamed to DateRecognizerFilter and moved under\nanalysis/common. TokenTypeSinkFilter was removed (use TypeTokenFilter instead).\nTokenRangeSinkFilter was removed.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6980", "change_description": ": Default applyAllDeletes to true when opening\nnear-real-time readers", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6981", "change_description": ": SpanQuery.getTermContexts() helper methods are now public, and\nSpanScorer has a public getSpans() method.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6932", "change_description": ": IndexInput.seek implementations now throw EOFException\nif you seek beyond the end of the file", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-6988", "change_description": ": IndexableField.tokenStream() no longer throws IOException", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "API Changes", "change_id": "LUCENE-7028", "change_description": ": Deprecate a duplicate method in NumericUtils.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6930", "change_description": ": Decouple GeoPointField from NumericType by using a custom\nand efficient GeoPointTokenStream and TermEnum designed for GeoPoint prefix\nterms.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6951", "change_description": ": Improve GeoPointInPolygonQuery using point orientation based\nline crossing algorithm, and adding result for multi-value docs when least\n1 point satisfies polygon criteria.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6889", "change_description": ": BooleanQuery.rewrite now performs some query optimization, in\nparticular to rewrite queries that look like: \"+*:* #filter\" to a\n\"ConstantScore(filter)\".", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6912", "change_description": ": Grouping's Collectors now calculate a response to needsScores()\ninstead of always 'true'.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6815", "change_description": ": DisjunctionScorer now advances two-phased iterators lazily,\nstopping to evaluate them as soon as a single one matches. The other iterators\nwill be confirmed lazily when computing score() or freq().", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6926", "change_description": ": MUST_NOT clauses now use the match cost API to run the slow bits\nlast whenever possible.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6944", "change_description": ": BooleanWeight no longer creates sub-scorers if BS1 is not\napplicable.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6940", "change_description": ": MUST_NOT clauses execute faster, especially when they are sparse.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Optimizations", "change_id": "LUCENE-6470", "change_description": ": Improve efficiency of TermsQuery constructors.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6976", "change_description": ": BytesRefTermAttributeImpl.copyTo NPE'ed if BytesRef was null.\nAdded equals & hashCode, and a new test for these things.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6932", "change_description": ": RAMDirectory's IndexInput was failing to throw\nEOFException in some cases", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6896", "change_description": ": Don't treat the smallest possible norm value as an infinitely\nlong document in SimilarityBase or BM25Similarity. Add more warnings to sims\nthat will not work well with extreme tf values.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6984", "change_description": ": SpanMultiTermQueryWrapper no longer modifies its wrapped query.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6998", "change_description": ": Fix a couple places to better detect truncated index files\nas corruption.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7002", "change_description": ": Fixed MultiCollector to not throw a NPE if setScorer is called\nafter one of the sub collectors is done collecting.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7027", "change_description": ": Fixed NumericTermAttribute to not throw IllegalArgumentException\nafter NumericTokenStream was exhausted.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7018", "change_description": ": Fix GeoPointTermQueryConstantScoreWrapper to add document on\nfirst GeoPointField match.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-7019", "change_description": ": Add two-phase iteration to GeoPointTermQueryConstantScoreWrapper.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Bug Fixes", "change_id": "LUCENE-6989", "change_description": ": Improve MMapDirectory's unmapping checks to catch more non-working\ncases. The unmap-hack does not yet work with recent Java 9. Official support\nwill come with Lucene 6.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6924", "change_description": ": Upgrade randomizedtesting to 2.3.2.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6920", "change_description": ": Improve custom function checks in expressions module\nto use MethodHandles and work without extra security privileges.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6921", "change_description": ": Fix SPIClassIterator#isParentClassLoader to don't\nrequire extra permissions.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6923", "change_description": ": Fix RamUsageEstimator to access private fields inside\nAccessController block for computing size.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6907", "change_description": ": make TestParser extendable, rename test/.../xml/\nNumericRangeQueryQuery.xml to NumericRangeQuery.xml", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6925", "change_description": ": add ForceMergePolicy class in test-framework", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6945", "change_description": ": factor out TestCorePlus(Queries|Extensions)Parser from\nTestParser, rename TestParser to TestCoreParser", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6949", "change_description": ": fix (potential) resource leak in SynonymFilterFactory\n(", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "https://scan.coverity.com/projects/5620", "change_description": ": fix (potential) resource leak in SynonymFilterFactory\n(", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6961", "change_description": ": Improve Exception handling in AnalysisFactories /\nAnalysisSPILoader: Don't wrap exceptions occuring in factory's\nctor inside InvocationTargetException.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6965", "change_description": ": Expression's JavascriptCompiler now throw ParseException\nwith bad function names or bad arity instead of IllegalArgumentException.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6964", "change_description": ": String-based signatures in JavascriptCompiler replaced\nwith better compile-time-checked MethodType; generated class files\nare no longer marked as synthetic.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6978", "change_description": ": Refactor several code places that lookup locales\nby string name to use BCP47 locale tag instead. LuceneTestCase\nnow also prints locales on failing tests this way.\nLocale#forLanguageTag() and Locale#toString() were placed on list\nof forbidden signatures.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-6988", "change_description": ": You can now add IndexableFields directly to a MemoryIndex,\nand create a MemoryIndex from a lucene Document.", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-7005", "change_description": ": TieredMergePolicy tweaks (>= vs. >, @see get vs. set)", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
{"library_version": "5.5.0", "change_type": "Other", "change_id": "LUCENE-7006", "change_description": ": increase BaseMergePolicyTestCase use (TestNoMergePolicy and\nTestSortingMergePolicy now extend it, TestUpgradeIndexMergePolicy added)", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "patch_link": "none", "patch_content": "none"}
