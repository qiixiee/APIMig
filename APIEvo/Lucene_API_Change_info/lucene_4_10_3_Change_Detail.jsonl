{"library_version": "4.10.3", "change_type": "Documentation", "change_id": "LUCENE-6057", "change_description": ": Improve Sort(SortField) docs", "change_title": "none", "detail_type": "none", "detail_affect_versions": "none", "detail_fix_versions": "none", "detail_description": "none", "link": "http://issues.apache.org/jira/browse/LUCENE-6057", "patch_link": "none", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6046", "change_description": ": Add maxDeterminizedStates safety to determinize (which has\nan exponential worst case) so that if it would create too many states, it\nnow throws an exception instead of exhausting CPU/RAM.", "change_title": "RegExp.toAutomaton high memory use", "detail_type": "Bug", "detail_affect_versions": "4.10.1", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "When creating an automaton from an org.apache.lucene.util.automaton.RegExp, it's possible for the automaton to use so much memory it exceeds the maximum array size for java. The following caused an OutOfMemoryError with a 32gb heap: When increased to a 60gb heap, the following exception is thrown:", "patch_link": "https://issues.apache.org/jira/secure/attachment/12679128/LUCENE-6046.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6054", "change_description": ": Allow repeating the empty automaton", "change_title": "RegExp.toAutomaton fails on #*", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "This throws an assertion error: new RegExp(\"#*\").toAutomaton(1000);", "patch_link": "none", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6049", "change_description": ": Don't throw cryptic exception writing a segment when\nthe only docs in it had fields that hit non-aborting exceptions\nduring indexing but also had doc values.", "change_title": "Cryptic exception if all docs in a segment hit non-aborting exceptions before adding their doc values", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "I hit this while working on LUCENE-6005: If you add a document with a single field that's both indexed and has doc values, and during inversion it hits a non-aborting exception, and all docs for a given segment had this happen, then you'll hit this confusing exception: The good news here is that exception is new from LUCENE-6019 and it prevents this case from causing index corruption, but the bad news is, you shouldn't even get an exception writing the segment in the first place.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12679656/LUCENE-6049.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6060", "change_description": ": Deprecate IndexWriter.unlock", "change_title": "Remove IndexWriter.unLock", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10,5.0,6.0", "detail_description": "This method used to be necessary, when our locking impls were buggy, but it's a godawful dangerous method: it invites index corruption. I think we should remove it. Apps that for some scary reason really need it can do their own thing...", "patch_link": "https://issues.apache.org/jira/secure/attachment/12681047/LUCENE-6060.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-3229", "change_description": ": Overlapping ordered SpanNearQuery spans should not match.", "change_title": "SpanNearQuery: ordered spans should not overlap", "detail_type": "Bug", "detail_affect_versions": "3.1", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "While using Span queries I think I've found a little bug. With a document like this (from the TestNearSpansOrdered unit test) : \"w1 w2 w3 w4 w5\" If I try to search for this span query : spanNear([spanNear([field:w3, field:w5], 1, true), field:w4], 0, true) the above document is returned and I think it should not because 'w4' is not after 'w5'. The 2 spans are not ordered, because there is an overlap. I will add a test patch in the TestNearSpansOrdered unit test. I will add a patch to solve this issue too. Basicaly it modifies the two docSpansOrdered functions to make sure that the spans does not overlap.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12681521/LUCENE-3229.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6004", "change_description": ": Don't highlight the LookupResult.key returned from\nAnalyzingInfixSuggester", "change_title": "Highlighting AnalyzingInfixSuggester skips non-highlighted key", "detail_type": "Bug", "detail_affect_versions": "4.10", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "when setting 'doHighlight' to true at AnalyzingInfixSuggester.lookup(..), both the key and the highlightKey inside the returned lookupresult are set to the highlighted string. See at AnalyzingInfixSuggester.createResults, line 530: if (doHighlight) else As I understand, the key should'nt be highlighted in any case, only the highlightKey.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12681554/LUCENE-6004.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6075", "change_description": ": Don't overflow int in SimpleRateLimiter", "change_title": "SimpleRateLimiter cast overflow results in Thread.sleep exception", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "SimpleRateLimiter.pause() uses an uncheck cast of longs to ints: Thread.sleep((int) (pauseNS/1000000), (int) (pauseNS % 1000000)); Although we check that pauseNS is positive, however if it's large enough the cast to int produces a negative value, causing Thread.sleep to throw an exception. We should protect for it.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12683346/LUCENE-6075.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-5980", "change_description": ": Don't let document length overflow.", "change_title": "IW positions check not quite right", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "I noticed this when working on LUCENE-5977. We only check that position doesn't overflow, not length. So a buggy analyzer can happily write a corrupt index (negative freq)", "patch_link": "https://issues.apache.org/jira/secure/attachment/12672193/LUCENE-5980.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6042", "change_description": ": CustomScoreQuery explain was incorrect in some cases,\nsuch as when nested inside a boolean query.", "change_title": "CustomScoreQuery Explain differs from the actual score when topLevelBoost is used.", "detail_type": "Bug", "detail_affect_versions": "4.8", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "CustomScoreQuery.java, doExplain has the following line: This multiplies the custom score query by just the boost of the current query, and not by which is the value that's actually used during scoring. This leads to drastically different scores in the debug info, relative to the actual score, when the query is a subquery of another one, like a BooleanQuery clause, with a non-1 boost.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12679141/LUCENE-6042.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-5948", "change_description": ": RateLimiter now fully inits itself on init.", "change_title": "Improve RateLimiters Initialization semantics", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "I was working on SOLR-6485 when I realized that the first time pause is called even if we write a lot of bytes pause doesn't work correctly because in SimpleRateLimiter.pause() lastNS is 0 and startNS is always more than targetNS. If we remove the following line from TestRateLimiter.testPause() then the test fails - Should we do one of the following ?  1. Initialize lastNS in the ctor 2. Add a method saying start() which does the same", "patch_link": "https://issues.apache.org/jira/secure/attachment/12669032/LUCENE-5948.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6055", "change_description": ": PayloadAttribute.clone() now does a deep clone of the underlying\nbytes.", "change_title": "PayloadAttribute.clone() should deep clone its BytesRef", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "PayloadAttribute.clone() does a shallow clone, unlike e.g. CharTermAttribute. Attributes should deep clone, otherwise capturing state isn't correct. In addition, both PA's and CTA's .clone() falsely documents that they do shallow cloning on purposes, so need to fix that too.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12680567/LUCENE-6055.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Bug fixes", "change_id": "LUCENE-6094", "change_description": ": Allow IW.rollback to stop ConcurrentMergeScheduler even\nwhen it's stalling because there are too many merges.", "change_title": "IW.rollback can take forever when CMS has stalled threads", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "4.10.3,5.0,6.0", "detail_description": "CMS hard-stalls incoming threads for denial-of-service protection when merging cannot keep up with whatever is producing new segments. When you call IW.rollback, it asks all merges to abort, and a running merge will periodically check to see if it should abort. However, a stalled merge fails to check, which means rollback can take indefinitely long; I've seen this in Elasticsearch causing shutdown to take > 10 sec.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12685490/LUCENE-6094.patch", "patch_content": "none"}
{"library_version": "4.10.3", "change_type": "Documentation", "change_id": "LUCENE-6057", "change_description": ": Improve Sort(SortField) docs", "change_title": "Clarify the Sort(SortField...) constructor)", "detail_type": "Improvement", "detail_affect_versions": "4.10.2,6.0", "detail_fix_versions": "4.10.2,5.0,6.0", "detail_description": "I don't really know which version this affects, but I clarified the documentation of the Sort(SortField...) constructor to ease the understanding for new users. Pull Request: https://github.com/apache/lucene-solr/pull/20", "patch_link": "https://issues.apache.org/jira/secure/attachment/12681314/LUCENE-6057.patch", "patch_content": "none"}
