{"library_version": "6.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-7755", "change_description": ": Fixed join queries to not reference IndexReaders, as it could\ncause leaks if they are cached.", "change_title": "Join queries should not reference IndexReaders.", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "6.5.1,6.6,7.0", "detail_description": "This is similar to LUCENE-7657 and can cause memory leaks when those queries are cached.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12860864/LUCENE-7755.patch", "patch_content": "none"}
{"library_version": "6.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-7749", "change_description": ": Made LRUQueryCache delegate the scoreSupplier method.", "change_title": "IndexOrDocValuesQuery not working with LRUQueryCache (?)", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "6.5.1,6.6,7.0", "detail_description": "I was experimenting with 6.5.0-SNAPSHOT and could not see any performance improvement using the new IndexOrDocValuesQuery where I would have expected some. I am using a basic FILTER query (term + point/dv range), along with IndexSearcher#search.  Looking at the stack trace it seems that LRUQueryCache#CachingWrapperWeight not delegating the scorerSupplier method is the reason. Maybe it is on purpose for the result to be cacheable ? Does that mean IndexOrDocValuesQuery is not useable with the default IndexSearcher cache ? (Or maybe am I just completely misusing the  IndexOrDocValuesQuery feature ?) Here is a thread dump of the call to IndexOrDocValuesQuery#scorerSupplier at org.apache.lucene.search.IndexOrDocValuesQuery$1.scorerSupplier(IndexOrDocValuesQuery.java:148) \t  at org.apache.lucene.search.IndexOrDocValuesQuery$1.scorer(IndexOrDocValuesQuery.java:168) \t  at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:746) \t  at org.apache.lucene.search.Weight.scorerSupplier(Weight.java:126) \t  at org.apache.lucene.search.BooleanWeight.scorerSupplier(BooleanWeight.java:400) \t  at org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:381) \t  at org.apache.lucene.search.Weight.bulkScorer(Weight.java:160) \t  at org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:375) \t  at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.cache(LRUQueryCache.java:704) \t  at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.bulkScorer(LRUQueryCache.java:787) \t  at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:666) \t  at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:473)", "patch_link": "https://issues.apache.org/jira/secure/attachment/12861456/LUCENE-7749.patch", "patch_content": "none"}
{"library_version": "6.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-7769", "change_description": ": The UnifiedHighligter wasn't highlighting portions of the query\nwrapped in BoostQuery or SpanBoostQuery.", "change_title": "UnifiedHighlighter doesn't highlight MTQs wrapped in BoostQuery", "detail_type": "Bug", "detail_affect_versions": "6.4.2,6.5", "detail_fix_versions": "6.5.1,7.0", "detail_description": "UnifiedHighlighter doesn't highlight MTQ wrapped in BoostQuery. For example, suppose we have a doc with a field 'f' contains data 'lucene'.  UnifiedHighlighter highlights query (f:lucene*), but query (f:lucene*)^1 doesn't. Test code: My opinion it's because MultiTermHighlighting.extractAutomata() returns an empty automaton for BoostQuery. I think, should add some thing like: to MultiTermHighlighting.extractAutomata() Thanks.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12862725/LUCENE_7769_MTQ_in_BoostQuery.patch", "patch_content": "none"}
{"library_version": "6.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-7777", "change_description": ": ByteBlockPool.readBytes sometimes throws\nArrayIndexOutOfBoundsException when byte blocks larger than 32 KB\nwere added", "change_title": "ByteBlockPool.readBytes incorrectly throws AIOOBE if length > 32768", "detail_type": "Bug", "detail_affect_versions": "None", "detail_fix_versions": "6.5.1,6.6,7.0", "detail_description": "I'm using Lucene's OfflineSorter to sort a large data set, and some of the items in the set are > 32 KB in length, which tickled a bug in its readBytes.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12862862/LUCENE-7777.patch", "patch_content": "none"}
{"library_version": "6.5.1", "change_type": "Bug Fixes", "change_id": "LUCENE-7791", "change_description": ": Fixed index sorting to work with sparse numeric and binary docvalues field.", "change_title": "AIOOBE on flush+sort", "detail_type": "Bug", "detail_affect_versions": "6.5", "detail_fix_versions": "6.5.1,6.6,7.0", "detail_description": "On released 6.5.0 version, flushing operation on sorted index throws ArrayIndexOutOfBoudException in NumericDocValuesWriter, NormValuesWriter and BinaryDocValuesWriter. New SortedXXXIterators are looking up documents in FixedBitSets or PackedValues based on remapped (sorted) document ID, without checking BitSets/Values ranges, which are based on original document IDs. Meanwhile FixedBitSets can be sparse not only in between documents with fields, but also after last (originally) document with given field (because writer's addValue() is not called for last documents without values for fields). So remapped (sorted) values range can have different useful values range and bounds checking should be done for remapped and not original ID. We were hit by this bug because our indexes are built from independent sources by partial updating fragments of documents, so there is always some documents without values in some fields. As I understand this bug, it shows when: Also, check for range of values for given field is now happening based on original ID (e.g. \"upto < size\"), so flushing can now lost some values, even without hitting AIOOBE. I will attach patch resolving issues with some writers; for other writers from LUCENE-7579, I am not sure if there are similar bugs in them; patch resolved our indexing issues, please check changes from LUCENE-7579 for confirmation of lack of additional bugs in other flush-sorting writers.", "patch_link": "https://issues.apache.org/jira/secure/attachment/12864331/LUCENE-7791.patch", "patch_content": "none"}
{"library_version": "6.5.1", "change_type": "Other", "change_id": "LUCENE-7763", "change_description": ": Remove outdated comment in IndexWriterConfig.setIndexSort javadocs.", "change_title": "remove outdated comment in IndexWriterConfig.setIndexSort javadocs", "detail_type": "Task", "detail_affect_versions": "6.5", "detail_fix_versions": "6.5.1", "detail_description": "马可阳 wrote on the dev mailing list: ... code comment out of date: Note that newly flushed segments will remain unsorted ... It is comment of method : setIndexSort in IndexWriterConfig.java. Code link is below: https://github.com/apache/lucene-solr/blob/master/lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig.java since issue “LUCENE-7579: sort segments at flush too” is already merged into code, this comment is out of date. ... The comment is included in the javadocs: http://lucene.apache.org/core/6_5_0/core/org/apache/lucene/index/IndexWriterConfig.html#setIndexSort-org.apache.lucene.search.Sort-", "patch_link": "none", "patch_content": "none"}
